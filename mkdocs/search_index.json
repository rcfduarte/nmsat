{
    "docs": [
        {
            "location": "/", 
            "text": "What is it?\n\n\nNMSAT is a Python package that provides a set of tools to build, simulate and analyse neuronal microcircuit models with any degree of complexity, as well as to probe the circuits with arbitrarily complex input stimuli / signals and to analyse the relevant functional aspects of single neuron, population and network dynamics. It provides a high-level wrapper for PyNEST (which is used as\nthe core simulation engine). As such, the complexity of the microcircuits analysed and their building blocks (neuron and synapse models, circuit topology and connectivity, etc.), are determined by the models available in NEST. The use of NEST allows efficient and highly scalable simulations of very\nlarge and complex circuits, constrained only by the computational resources available to the user.\nThe modular design allows the user to specify numerical experiments with varying degrees of\ncomplexity depending on concrete research objectives. The generality of some of these experiments\nallows the same types of measurements to be performed on a variety of different circuits, which can\nbe useful for benchmarking and comparison purposes. Additionally, the code was designed to allow\nan effortless migration across computing systems, i.e. the same simulations can be executed in a\nlocal machine, in a computer cluster or a supercomputer, with straightforward resource allocation\n(see \nkernel parameters\n).\n\n\nThe code is licensed under GPLv2 and available on \nGitHub\n.\n\n\nDisclaimer\n\n\nThe code was developed primarily for personal use, as part of a PhD project due to the need to perform similar experiments and analyses on very diverse systems. The goal was to use the same code to\nrun different, but specialized, numerical experiments, in a fully transparent and reproducible manner, while making efficient use of computing resources. Due to the inherent time pressures of a PhD project and the broad scope, the code and documentation are under active use / development. \n\n\nAuthors and contributors\n\n\n\n\nRenato Duarte\n\n\nBarna Zajzon\n\n\n\n\nCiting us\n\n\nIf you find NMSAT helpful and use it in your research, please cite it as [zenodo]\n\n\nAcknowledgements\n\n\nThis work was done in the \nFunctional Neural Circuits\n group, at the Institute for Neuroscience and Medicine (INM-6) and Institute for Advanced Simulation (IAS-6), J\u00fclich Research Centre, J\u00fclich, Germany. \nWe would like to thank Professor Abigail Morrison for her continued patience, advice and support and the \nNeurobiology of Language\n group, at the Max-Planck for Psycholinguistics, for valuable discussions and contributions.\n\n\nWe acknowledge partial support by the Erasmus Mundus Joint Doctoral Program EuroSPIN, the German Ministry for Education and Research (Bundesministerium f\u00fcr Bildung und Forschung) BMBF Grant 01GQ0420 to BCCN Freiburg, the Helmholtz Alliance on Systems Biology (Germany), the Initiative and Networking Fund of the Helmholtz Association, the Helmholtz Portfolio theme \u2018Supercomputing and Modeling for the Human Brain\u2019.\nWe additionally acknowledge the computing time granted by the JARA-HPC Vergabegremium on the supercomputer \nJURECA\n at Forschungszentrum J\u00fclich, used during development.", 
            "title": "Overview"
        }, 
        {
            "location": "/#what-is-it", 
            "text": "NMSAT is a Python package that provides a set of tools to build, simulate and analyse neuronal microcircuit models with any degree of complexity, as well as to probe the circuits with arbitrarily complex input stimuli / signals and to analyse the relevant functional aspects of single neuron, population and network dynamics. It provides a high-level wrapper for PyNEST (which is used as\nthe core simulation engine). As such, the complexity of the microcircuits analysed and their building blocks (neuron and synapse models, circuit topology and connectivity, etc.), are determined by the models available in NEST. The use of NEST allows efficient and highly scalable simulations of very\nlarge and complex circuits, constrained only by the computational resources available to the user.\nThe modular design allows the user to specify numerical experiments with varying degrees of\ncomplexity depending on concrete research objectives. The generality of some of these experiments\nallows the same types of measurements to be performed on a variety of different circuits, which can\nbe useful for benchmarking and comparison purposes. Additionally, the code was designed to allow\nan effortless migration across computing systems, i.e. the same simulations can be executed in a\nlocal machine, in a computer cluster or a supercomputer, with straightforward resource allocation\n(see  kernel parameters ).  The code is licensed under GPLv2 and available on  GitHub .", 
            "title": "What is it?"
        }, 
        {
            "location": "/#disclaimer", 
            "text": "The code was developed primarily for personal use, as part of a PhD project due to the need to perform similar experiments and analyses on very diverse systems. The goal was to use the same code to\nrun different, but specialized, numerical experiments, in a fully transparent and reproducible manner, while making efficient use of computing resources. Due to the inherent time pressures of a PhD project and the broad scope, the code and documentation are under active use / development.", 
            "title": "Disclaimer"
        }, 
        {
            "location": "/#authors-and-contributors", 
            "text": "Renato Duarte  Barna Zajzon", 
            "title": "Authors and contributors"
        }, 
        {
            "location": "/#citing-us", 
            "text": "If you find NMSAT helpful and use it in your research, please cite it as [zenodo]", 
            "title": "Citing us"
        }, 
        {
            "location": "/#acknowledgements", 
            "text": "This work was done in the  Functional Neural Circuits  group, at the Institute for Neuroscience and Medicine (INM-6) and Institute for Advanced Simulation (IAS-6), J\u00fclich Research Centre, J\u00fclich, Germany. \nWe would like to thank Professor Abigail Morrison for her continued patience, advice and support and the  Neurobiology of Language  group, at the Max-Planck for Psycholinguistics, for valuable discussions and contributions.  We acknowledge partial support by the Erasmus Mundus Joint Doctoral Program EuroSPIN, the German Ministry for Education and Research (Bundesministerium f\u00fcr Bildung und Forschung) BMBF Grant 01GQ0420 to BCCN Freiburg, the Helmholtz Alliance on Systems Biology (Germany), the Initiative and Networking Fund of the Helmholtz Association, the Helmholtz Portfolio theme \u2018Supercomputing and Modeling for the Human Brain\u2019.\nWe additionally acknowledge the computing time granted by the JARA-HPC Vergabegremium on the supercomputer  JURECA  at Forschungszentrum J\u00fclich, used during development.", 
            "title": "Acknowledgements"
        }, 
        {
            "location": "/installation/", 
            "text": "Download\n\n\nWe currently don\u2019t provide the code as a standard library that can be easily installed. In future\nversions, we will try to work on this and improve usability. For the moment, to use the code there is\nno explicit installation involved. Just fork and clone the Github repository from \nhere.\n\n\nDependencies\n\n\n\n\nPython\n 2.7\n\n\nNEST\n version 2.8.0 or higher\n\n\nnumpy\n version 1.7.0 or higher \n\n\nscipy\n version 0.12.0 or higher\n\n\nscikit-learn\n version 0.18.0 or higher\n\n\nmatplotlib\n version 1.2.0 or higher\n\n\n\n\nOptional (for additional functionality):\n\n\n\n\nPySpike\n version 0.5.1\n\n\nh5py\n version 2.2.1 or higher\n\n\nmayavi\n version 4.0 or higher\n\n\nnetworkx\n version 1.1\n\n\n\n\nGetting Started\n\n\nAfter downloading the repository, the framework's configure file, which sets the correct paths, needs to be sourced:\n\n\nsource\n /\n{\npath\n}\n/nmsat/configure.sh\n\n\n\n\n\nwhere \n{path}\n refers to the full path to the main NMSAT directory in your system.\nThis last step requires the user to manually specify all the paths for his system, by editing the paths dictionary in \n\n/defaults/paths.py\n, as:\n\n\npaths\n \n=\n \n{\n\n    \nsystem_label\n:\n \n{\n\n        \ndata_path\n:\n            \nNMSAT_HOME\n \n+\n \n/data/\n,\n\n        \njdf_template\n:\n         \nNMSAT_HOME\n \n+\n \n/defaults/cluster_templates/Cluster_jdf.sh\n,\n\n        \nmatplotlib_rc\n:\n        \nNMSAT_HOME\n \n+\n \n/defaults/matplotlib_rc\n,\n\n        \nremote_directory\n:\n     \nNMSAT_HOME\n \n+\n \n/export/\n,\n\n        \nqueueing_system\n:\n      \nslurm\n}\n\n        \n}\n\n\n\n\n\n\nThe \nsystem_label\n specifies the name of the system. If running simulations on a local machine, the name must be set as 'local' (which is the default), otherwise, it can be any arbitrary name, as long as it is used consistently throughout (see examples). The remaining entries in this dictionary refer to:\n\n\n\n\ndata_path\n - specify where to store the output data generated by an experiment\n\n\njdf_template\n - path to a system-specific job description file (see example in /defaults/cluster_templates); if running locally set to None\n\n\nmatplotlibrc\n - in case the user wants to customize \nmatplotlib\n\n\nremote_directory\n - folder where the job submission files will be written (only applicable if not running locally, but must be specified anyway)\n\n\nqueueing_system\n - type of job schedulling system used (current options include only 'slurm' and 'sge').\n\n\n\n\nAnd that should be it. After specifying all these for the systems where the code is intended to be executed, it should be possible to run the framework (see \nstandard use case\n).", 
            "title": "Installation"
        }, 
        {
            "location": "/installation/#download", 
            "text": "We currently don\u2019t provide the code as a standard library that can be easily installed. In future\nversions, we will try to work on this and improve usability. For the moment, to use the code there is\nno explicit installation involved. Just fork and clone the Github repository from  here.", 
            "title": "Download"
        }, 
        {
            "location": "/installation/#dependencies", 
            "text": "Python  2.7  NEST  version 2.8.0 or higher  numpy  version 1.7.0 or higher   scipy  version 0.12.0 or higher  scikit-learn  version 0.18.0 or higher  matplotlib  version 1.2.0 or higher   Optional (for additional functionality):   PySpike  version 0.5.1  h5py  version 2.2.1 or higher  mayavi  version 4.0 or higher  networkx  version 1.1", 
            "title": "Dependencies"
        }, 
        {
            "location": "/installation/#getting-started", 
            "text": "After downloading the repository, the framework's configure file, which sets the correct paths, needs to be sourced:  source  / { path } /nmsat/configure.sh  where  {path}  refers to the full path to the main NMSAT directory in your system.\nThis last step requires the user to manually specify all the paths for his system, by editing the paths dictionary in  /defaults/paths.py , as:  paths   =   { \n     system_label :   { \n         data_path :              NMSAT_HOME   +   /data/ , \n         jdf_template :           NMSAT_HOME   +   /defaults/cluster_templates/Cluster_jdf.sh , \n         matplotlib_rc :          NMSAT_HOME   +   /defaults/matplotlib_rc , \n         remote_directory :       NMSAT_HOME   +   /export/ , \n         queueing_system :        slurm } \n         }   The  system_label  specifies the name of the system. If running simulations on a local machine, the name must be set as 'local' (which is the default), otherwise, it can be any arbitrary name, as long as it is used consistently throughout (see examples). The remaining entries in this dictionary refer to:   data_path  - specify where to store the output data generated by an experiment  jdf_template  - path to a system-specific job description file (see example in /defaults/cluster_templates); if running locally set to None  matplotlibrc  - in case the user wants to customize  matplotlib  remote_directory  - folder where the job submission files will be written (only applicable if not running locally, but must be specified anyway)  queueing_system  - type of job schedulling system used (current options include only 'slurm' and 'sge').   And that should be it. After specifying all these for the systems where the code is intended to be executed, it should be possible to run the framework (see  standard use case ).", 
            "title": "Getting Started"
        }, 
        {
            "location": "/framework-description/", 
            "text": "NMSAT architecture overview:\n\n\n\nThe framework is built on a modular structure, which can be divided into six main elements (the core modules):\n\n\n\n\n\n\nParameters:\n complex nested dictionaries, specified as an independent file. Typically this is the most sensitive aspect of the whole framework as the structure and contents of these dictionaries determines all the specificities of the experiments. Different sub-dictionaries should be created for each type of parameters (see \nparameters\n)\n\n\n\n\n\n\nInput Architect:\n handles all the generation and preprocessing of input stimuli and signals. Being quite flexible, it is difficult to describe a single workflow for Input Architect, but in the relatively complex scenario illustrated above, it would consist of a \nStimulusSet\n object, which wraps multiple stimulus sequences (as labelled, binary feature vectors, subdivided into train and test set, for example), an \nInputSignalSet\n, which contains all the input signals generated from the stimulus sequences, according to the chosen transduction strategy, as well as instances of input noise which can be added to the signal or provided as an independent input. Finally, the \nEncodingLayer\n consists of generators (NEST devices) and/or encoders (Population objects, typically spiking neurons). Note that, any of these components can be removed or manually specified, for example, it may be important to provide a very specific \nInputSignal\n, which can be loaded as a numpy array. In this alternative scenario, the \nStimulusSet\n would be unnecessary. Stimulus sets can also be manually generated and loaded onto the framework.\n\n\n\n\n\n\nNetwork Architect:\n \n\n\n\n\n\n\nAnalysis:\n\n\n\n\n\n\nNote that, depending on the experiment, not all of the components are necessary and it is frequently the case that only sub-sets of these modules are used in a given experiment (see \nexamples\n), depending on the nature of the input stimuli (if any), the nature of the circuit and what is intended to be measured.\n\n\nCode structure\n\n\nThe code is organized as follows:\n\n\n\u251c\u2500\u2500 nmsat\n\u2502   \u251c\u2500\u2500 modules\n\u2502   \u2502   \u251c\u2500\u2500 parameters.py\n\u2502   \u2502   \u251c\u2500\u2500 input_architect.py\n\u2502   \u2502   \u251c\u2500\u2500 net_architect.py\n\u2502   \u2502   \u251c\u2500\u2500 signals.py\n\u2502   \u2502   \u251c\u2500\u2500 analysis.py\n\u2502   \u2502   \u251c\u2500\u2500 visualization.py\n\u2502   \u2502   \u251c\u2500\u2500 io.py\n\u2502   \u251c\u2500\u2500 defaults\n\u2502   \u2502   \u251c\u2500\u2500 paths.py\n\u2502   \u2502   \u251c\u2500\u2500 matplotlib_rc\n\u2502   \u2502   \u251c\u2500\u2500 cluster_templates\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cluster_jdf.sh\n\u2502   \u251c\u2500\u2500 data\n\u2502   \u251c\u2500\u2500 projects\n\u2502   \u2502   \u251c\u2500\u2500 project_name\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 computations\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 parameters\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 preset\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 scripts\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 read_data\n\u2502   \u251c\u2500\u2500 export\n\n\n\n\n\nThe core functionality lies in the modules packages, which contain all the relevant classes and\nfunctions used. The specifics will be explained in greater detail below, but in general the modules\nare responsible for:\n\n\n\n\nparameters\n - parsing and preparing all parameters files; retrieving stored parameter sets and\nspaces and harvesting data\n\n\ninput_architect\n - generating and setting up all the relevant input stimuli and signals; handling\ninput data; generating and connecting input encoding layers\n\n\nnet_architect\n - generating specific networks and neuronal populations; generating all connectivity and topology features; \nconnecting populations; ...\n\n\nsignals\n - wrapping and processing the various signal types used in the framework (spiking activity,\nanalog variables, etc)\n\n\nanalysis\n - post-processing and analysing population activity in various ways\n\n\nvisualization\n - plotting routines\n\n\nio\n - loading and saving data", 
            "title": "Quick overview"
        }, 
        {
            "location": "/framework-description/#nmsat-architecture-overview", 
            "text": "The framework is built on a modular structure, which can be divided into six main elements (the core modules):    Parameters:  complex nested dictionaries, specified as an independent file. Typically this is the most sensitive aspect of the whole framework as the structure and contents of these dictionaries determines all the specificities of the experiments. Different sub-dictionaries should be created for each type of parameters (see  parameters )    Input Architect:  handles all the generation and preprocessing of input stimuli and signals. Being quite flexible, it is difficult to describe a single workflow for Input Architect, but in the relatively complex scenario illustrated above, it would consist of a  StimulusSet  object, which wraps multiple stimulus sequences (as labelled, binary feature vectors, subdivided into train and test set, for example), an  InputSignalSet , which contains all the input signals generated from the stimulus sequences, according to the chosen transduction strategy, as well as instances of input noise which can be added to the signal or provided as an independent input. Finally, the  EncodingLayer  consists of generators (NEST devices) and/or encoders (Population objects, typically spiking neurons). Note that, any of these components can be removed or manually specified, for example, it may be important to provide a very specific  InputSignal , which can be loaded as a numpy array. In this alternative scenario, the  StimulusSet  would be unnecessary. Stimulus sets can also be manually generated and loaded onto the framework.    Network Architect:      Analysis:    Note that, depending on the experiment, not all of the components are necessary and it is frequently the case that only sub-sets of these modules are used in a given experiment (see  examples ), depending on the nature of the input stimuli (if any), the nature of the circuit and what is intended to be measured.", 
            "title": "NMSAT architecture overview:"
        }, 
        {
            "location": "/framework-description/#code-structure", 
            "text": "The code is organized as follows:  \u251c\u2500\u2500 nmsat\n\u2502   \u251c\u2500\u2500 modules\n\u2502   \u2502   \u251c\u2500\u2500 parameters.py\n\u2502   \u2502   \u251c\u2500\u2500 input_architect.py\n\u2502   \u2502   \u251c\u2500\u2500 net_architect.py\n\u2502   \u2502   \u251c\u2500\u2500 signals.py\n\u2502   \u2502   \u251c\u2500\u2500 analysis.py\n\u2502   \u2502   \u251c\u2500\u2500 visualization.py\n\u2502   \u2502   \u251c\u2500\u2500 io.py\n\u2502   \u251c\u2500\u2500 defaults\n\u2502   \u2502   \u251c\u2500\u2500 paths.py\n\u2502   \u2502   \u251c\u2500\u2500 matplotlib_rc\n\u2502   \u2502   \u251c\u2500\u2500 cluster_templates\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cluster_jdf.sh\n\u2502   \u251c\u2500\u2500 data\n\u2502   \u251c\u2500\u2500 projects\n\u2502   \u2502   \u251c\u2500\u2500 project_name\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 computations\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 parameters\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 preset\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 scripts\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 read_data\n\u2502   \u251c\u2500\u2500 export  The core functionality lies in the modules packages, which contain all the relevant classes and\nfunctions used. The specifics will be explained in greater detail below, but in general the modules\nare responsible for:   parameters  - parsing and preparing all parameters files; retrieving stored parameter sets and\nspaces and harvesting data  input_architect  - generating and setting up all the relevant input stimuli and signals; handling\ninput data; generating and connecting input encoding layers  net_architect  - generating specific networks and neuronal populations; generating all connectivity and topology features; \nconnecting populations; ...  signals  - wrapping and processing the various signal types used in the framework (spiking activity,\nanalog variables, etc)  analysis  - post-processing and analysing population activity in various ways  visualization  - plotting routines  io  - loading and saving data", 
            "title": "Code structure"
        }, 
        {
            "location": "/standard-use-case/", 
            "text": "A numerical experiment in this framework consists of 2 or 3 main files (see Examples section):\n\n\n\n\nparameters_file\n - specifying all the complex parameter sets and dictionaries required to set up\nthe experiment.\n\n\nexperiment_script\n - mostly used during development, for testing and debugging purposes.\nThese scripts parse the parameters_file and run the complete experiment\n\n\ncomputation_file\n - after the development and testing phase is completed, the experiment can\nbe copied to a computation_file, which can be used from the main... (*)\n\n\n\n\nThese files should be stored within a \nproject/\n folder, and in the \nparameters/\n, \nscripts/\n and \ncomputations/\n \nfolders, respectively.\n\n\nRunning an experiment\n\n\nThe way in which an experiment is run depends on the system used:\n\n\nLocal machine\n\n\nJust go to the main \nnmsat/\n directory and execute the experiment as:\n\n\npython main.py -f \n{\nparameters_file\n}\n -c \n{\ncomputation_function\n}\n --extra \n{\nextra_parameters\n}\n\n\n\n\n\n\nwhere \nparameters_file\n refers to the (full or relative) path to the parameters file for the experiment,\n\ncomputation_function\n is the name of the computation function to be executed on that parameter\nset (must match the name of a file in the project\u2019s \ncomputations/\n folder) and \nextra_parameters\n are\nparameter=value pairs for different, extra parameters (specific to each computation).\n\n\nCluster\n\n\nOn a computer cluster or supercomputer, the execution of the framework has a slightly different meaning. \nInstead of executing the code, it generates a series of files that can be used to submit the jobs to the system\u2019s scheduler.\n\n\nTo do this:\n\n\n\n\nadd an entry to \nnmsat/defaults/paths.py\n for your template (here \u2019Blaustein\u2019)\n\n\nadapt the default cluster template in \nnmsat/defaults/cluster_templates/Blaustein_jdf.sh\n\nto match your cluster requirements\n\n\nchange \nrun=\u2019local\u2019\n to \nrun=\u2019Blaustein\u2019\n in your parameter script\n\n\nexecute the following command from \nnmsat/\n\n\n\n\npython\n \nmain\n.\npy\n \n-\nf\n \n{\nparameters_file\n}\n \n-\nc\n \n{\ncomputation_function\n}\n \n--\nextra\n \n{\nextra_parameters\n}\n \n--\ncluster\n=\nBlaustein\n\n\n\n\n\n\n\n\ngo to \nnmsat/export/my_project_name/\n and submit jobs  via\n\n\n\n\npython\n \nsubmit_jobs\n.\npy\n \n0\n \n1\n\n\n\n\n\n\nSimulation output\n\n\nAfter a simulation is completed, all the relevant output data is stored in the pre-specified data_path,\nwithin a folder named after the project label. The output data structure is organized as follows:\n\n\ndata\n\u251c\u2500\u2500 experiment_label\n\u2502   \u251c\u2500\u2500 Figures\n\u2502   \u251c\u2500\u2500 Results\n\u2502   \u251c\u2500\u2500 Parameters\n\u2502   \u251c\u2500\u2500 Activity\n\u2502   \u251c\u2500\u2500 Input\n\u2502   \u251c\u2500\u2500 Output\n\n\n\n\n\nAnalysing and plotting\n\n\nAnalysis and plotting can be (and usually is) done within the main computation, so as to extract and\nstore only the information that is relevant for the specific experiment. Multiple, standard analysis and\nplotting routines are implemented for various complex experiments, with specific objectives. Naturally,\nthis is highly mutable as new experiments always require specific analyses methods.\n\n\nAlternatively, as all the relevant data is stored in the results dictionaries, you can read it and\nprocess it offline, applying the same or novel visualization routines.\n\n\nHarvesting stored results\n\n\nThe Results folder stores all the simulation results for the given experiment, as pickle dictionaries.\nWithin each project, as mentioned earlier, a read_data folder should be included, which contains files\nto parse and extract the stored results (see examples).\n\n\nproject\n      \n=\n \nproject_name\n\n\ndata_path\n    \n=\n \n/path/label/\n\n\ndata_label\n   \n=\n \nexample1\n\n\nresults_path\n \n=\n \ndata_path\n \n+\n \ndata_label\n \n+\n \n/Results/\n\n\n\n# set defaults and paths\n\n\nset_project_paths\n(\nproject\n)\n\n\nset_global_rcParams\n(\npaths\n[\nlocal\n][\nmatplotlib_rc\n])\n\n\n\n# re-create ParameterSpace\n\n\npars_file\n \n=\n \ndata_path\n \n+\n \ndata_label\n \n+\n \n_ParameterSpace.py\n\n\npars\n \n=\n \nParameterSpace\n(\npars_file\n)\n\n\n\n# print the full nested structure of the results dictionaries\n\n\npars\n.\nprint_stored_keys\n(\nresults_path\n)\n\n\n\n# harvest a specific result based on the results structure\n\n\ndata_array\n \n=\n \npars\n.\nharvest\n(\nresults_path\n,\n \nkey_set\n=\ndict_key1/dict_key1.1/dict_key1.1.1\n)", 
            "title": "Standard use case"
        }, 
        {
            "location": "/standard-use-case/#running-an-experiment", 
            "text": "The way in which an experiment is run depends on the system used:", 
            "title": "Running an experiment"
        }, 
        {
            "location": "/standard-use-case/#local-machine", 
            "text": "Just go to the main  nmsat/  directory and execute the experiment as:  python main.py -f  { parameters_file }  -c  { computation_function }  --extra  { extra_parameters }   where  parameters_file  refers to the (full or relative) path to the parameters file for the experiment, computation_function  is the name of the computation function to be executed on that parameter\nset (must match the name of a file in the project\u2019s  computations/  folder) and  extra_parameters  are\nparameter=value pairs for different, extra parameters (specific to each computation).", 
            "title": "Local machine"
        }, 
        {
            "location": "/standard-use-case/#cluster", 
            "text": "On a computer cluster or supercomputer, the execution of the framework has a slightly different meaning. \nInstead of executing the code, it generates a series of files that can be used to submit the jobs to the system\u2019s scheduler.  To do this:   add an entry to  nmsat/defaults/paths.py  for your template (here \u2019Blaustein\u2019)  adapt the default cluster template in  nmsat/defaults/cluster_templates/Blaustein_jdf.sh \nto match your cluster requirements  change  run=\u2019local\u2019  to  run=\u2019Blaustein\u2019  in your parameter script  execute the following command from  nmsat/   python   main . py   - f   { parameters_file }   - c   { computation_function }   -- extra   { extra_parameters }   -- cluster = Blaustein    go to  nmsat/export/my_project_name/  and submit jobs  via   python   submit_jobs . py   0   1", 
            "title": "Cluster"
        }, 
        {
            "location": "/standard-use-case/#simulation-output", 
            "text": "After a simulation is completed, all the relevant output data is stored in the pre-specified data_path,\nwithin a folder named after the project label. The output data structure is organized as follows:  data\n\u251c\u2500\u2500 experiment_label\n\u2502   \u251c\u2500\u2500 Figures\n\u2502   \u251c\u2500\u2500 Results\n\u2502   \u251c\u2500\u2500 Parameters\n\u2502   \u251c\u2500\u2500 Activity\n\u2502   \u251c\u2500\u2500 Input\n\u2502   \u251c\u2500\u2500 Output", 
            "title": "Simulation output"
        }, 
        {
            "location": "/standard-use-case/#analysing-and-plotting", 
            "text": "Analysis and plotting can be (and usually is) done within the main computation, so as to extract and\nstore only the information that is relevant for the specific experiment. Multiple, standard analysis and\nplotting routines are implemented for various complex experiments, with specific objectives. Naturally,\nthis is highly mutable as new experiments always require specific analyses methods.  Alternatively, as all the relevant data is stored in the results dictionaries, you can read it and\nprocess it offline, applying the same or novel visualization routines.", 
            "title": "Analysing and plotting"
        }, 
        {
            "location": "/standard-use-case/#harvesting-stored-results", 
            "text": "The Results folder stores all the simulation results for the given experiment, as pickle dictionaries.\nWithin each project, as mentioned earlier, a read_data folder should be included, which contains files\nto parse and extract the stored results (see examples).  project        =   project_name  data_path      =   /path/label/  data_label     =   example1  results_path   =   data_path   +   data_label   +   /Results/  # set defaults and paths  set_project_paths ( project )  set_global_rcParams ( paths [ local ][ matplotlib_rc ])  # re-create ParameterSpace  pars_file   =   data_path   +   data_label   +   _ParameterSpace.py  pars   =   ParameterSpace ( pars_file )  # print the full nested structure of the results dictionaries  pars . print_stored_keys ( results_path )  # harvest a specific result based on the results structure  data_array   =   pars . harvest ( results_path ,   key_set = dict_key1/dict_key1.1/dict_key1.1.1 )", 
            "title": "Harvesting stored results"
        }, 
        {
            "location": "/parameters/", 
            "text": "The implementation of the simulator relies entirely on the structure of the parameters dictionaries,\nwhich makes the correct specification of the parameters files the most sensitive (and error-prone)\naspect. The main modules simply extract the specifications described in these dictionaries and set-up\nthe experiment. So, the most critical step in setting up a numerical experiment with the current\nimplementation is the correct specification of all the complex parameter sets. In this section, we\nexplain the main features that all parameters must obey to and exemplify how the parameters file\ncontaining all the dictionaries should be set up. However, different experiments can have very different\nrequirements and specifications (see examples). It is important to reinforce that the structure of these\ndictionaries is the critical element to make everything work. If the naming conventions used are broken,\nerrors will follow.\n\n\nFurthermore, modifications of the parameter values are accepted with some restrictions, depending\non what is currently implemented.\n\n\nWe start with a trimmed version of the parameter file in the \nfI curve example\n, to explain the its basic components and structure:\n\n\nfrom\n \ndefaults.paths\n \nimport\n \npaths\n\n\nfrom\n \nmodules.parameters\n \nimport\n \nParameterSet\n,\n \ncopy_dict\n\n\n\nsystem_name\n \n=\n \nlocal\n\n\ndata_label\n  \n=\n \nexample1_singleneuron_fI\n\n\n\n# ######################################################################################################################\n\n\n# PARAMETER RANGE declarations\n\n\n# ======================================================================================================================\n\n\nparameter_range\n \n=\n \n{\n\n    \nmax_current\n:\n \n[\n800.\n]\n\n\n}\n\n\n\n\ndef\n \nbuild_parameters\n(\nmax_current\n):\n\n    \n# ##################################################################################################################\n\n    \n# DC input parameters\n\n    \n# ==================================================================================================================\n\n    \ntotal_time\n \n=\n \n10000.\n        \n# total simulation time [ms]\n\n    \nanalysis_interval\n \n=\n \n1000.\n  \n# duration of each current step [ms]\n\n    \nmin_current\n \n=\n \n0.\n           \n# initial current amplitude [pA]\n\n\n\n    \n# ##################################################################################################################\n\n    \n# System / Kernel Parameters\n\n    \n# ##################################################################################################################\n\n    \n# system-specific parameters (resource allocation, simulation times)\n\n    \nsystem_pars\n \n=\n \ndict\n(\n\n        \nnodes\n=\n1\n,\n\n        \n...\n\n    \n)\n\n\n    \n# main kernel parameter set\n\n    \nkernel_pars\n \n=\n \nParameterSet\n({\n\n        \nresolution\n:\n \n0.1\n,\n\n        \n...\n\n    \n})\n\n    \n# ##################################################################################################################\n\n    \n# Recording devices\n\n    \n# ##################################################################################################################\n\n    \nmultimeter\n \n=\n \n{\n\n        \nstart\n:\n \n0.\n,\n\n        \nstop\n:\n \nsys\n.\nfloat_info\n.\nmax\n,\n\n        \n...\n\n    \n}\n\n\n    \n# ##################################################################################################################\n\n    \n# Neuron, Synapse and Network Parameters\n\n    \n# ##################################################################################################################\n\n    \nneuron_pars\n \n=\n \n{\n\n        \nAdEx\n:\n \n{\n\n                \nmodel\n:\n \naeif_cond_exp\n,\n\n                \nC_m\n:\n \n250.0\n,\n\n                \n...\n\n        \n}\n\n    \n}\n\n\n    \nnet_pars\n \n=\n \nParameterSet\n({\n\n        \nn_populations\n:\n \nlen\n(\nneuron_pars\n.\nkeys\n()),\n\n        \npop_names\n:\n \npop_names\n,\n\n        \n...\n\n    \n})\n\n\n    \nneuron_pars\n \n=\n \nParameterSet\n(\nneuron_pars\n)\n\n\n    \n# ##################################################################################################################\n\n    \n# Input/Encoding Parameters\n\n    \n# ##################################################################################################################\n\n    \nencoding_pars\n \n=\n \nParameterSet\n({\n\n        \ngenerator\n:\n \n{\n\n            \nN\n:\n \n1\n,\n\n            \nlabels\n:\n \n[\nDC_Input\n],\n\n            \nmodels\n:\n \n[\nstep_current_generator\n],\n\n        \n}\n\n        \n...\n\n    \n})\n\n\n    \n# ##################################################################################################################\n\n    \n# Return dictionary of Parameters dictionaries\n\n    \n# ==================================================================================================================\n\n    \nreturn\n \ndict\n([(\nkernel_pars\n,\n    \nkernel_pars\n),\n\n                 \n(\nneuron_pars\n,\n    \nneuron_pars\n),\n\n                 \n(\nnet_pars\n,\n       \nnet_pars\n),\n\n                 \n(\nencoding_pars\n,\n  \nencoding_pars\n)])\n\n\n\n\n\n\nTypically the following imports are necessary in a parameter file:\n\n\nfrom\n \ndefaults.paths\n \nimport\n \npaths\n  \n\nfrom\n \nmodules.parameters\n \nimport\n \nParameterSet\n\n\n\n\n\n\nThe experiment label and the system in which the experiments will run need to be specified and\nwill determine the system-specific paths to use as well as the label for data storage:\n\n\nsystem_name\n \n=\n \nlocal\n\n\ndata_label\n  \n=\n \nexample1_singleneuron_fI\n\n\n\n\n\n\nIt is important to make sure that the \nsystem_name\n corresponds to a key in the \npaths\n dictionary.\nAlso, it is always advisable to provide appropriate labels for the data.\n\n\nParameter range declarations and build function\n\n\nNMSAT allows the definition of ranges for the values of various parameters of choice via the \nparameter_range\n dictionary,\nin order simplify running the same experiment when only some parameter values change:\n\n\nparameter_range\n \n=\n \n{\n\n    \nmax_current\n:\n \n[\n800.\n]\n\n\n}\n\n\n\ndef\n \nbuild_parameters\n(\nmax_current\n):\n\n    \n...\n\n\n\n\nIn this case, only one simulation will be executed where \nmax_current = 800.\n. However, the following code \n\n\nparameter_range\n \n=\n \n{\n\n    \nmax_current\n:\n \n[\n800.\n,\n \n1200.\n],\n\n    \ntotal_time\n:\n \n[\n1000.\n]\n\n\n}\n\n\n\ndef\n \nbuild_parameters\n(\nmax_current\n,\n \ntotal_time\n):\n\n    \n...\n\n\n\n\n\n\nwill result in 2 separate runs, one for each parameter combination:\n\n\n\n\nmax_current = 800., total_time = 1000.\n\n\nmax_current = 1200., total_time = 1000.\n\n\n\n\nThe \nbuild_parameters(...)\n function is required in every parameter file. If the \nparameter_range\n dictionary is not \nempty, its keys (more precisely equivalent variable names) must be passed as arguments to the \nbuild_parameters\n function.\n\n\nParameter types\n\n\nThe returned value of the \nbuild_parameters(...)\n function is a dictionary of \nParameterSets\n, containing all the\nnecessary types of parameters to be used by the main experiment. These parameters defined in the function are themselves\n\nParameterSets\n dictionaries:\n\n\nreturn\n \ndict\n([(\nkernel_pars\n,\n   \nkernel_pars\n),\n\n             \n(\nneuron_pars\n,\n   \nneuron_pars\n),\n\n             \n(\nnet_pars\n,\n      \nnet_pars\n),\n\n             \n(\nencoding_pars\n,\n \nencoding_pars\n)])\n\n\n\n\n\n\nEach key in the returned dictionary must match the name of the variable. Acceptable types (with examples of use) are: \n\n\nKernel\n\n\nSpecifies all relevant system and simulation parameters.\n\n\nkernel_pars\n \n=\n \nParameterSet\n({\n\n    \nresolution\n:\n \n0.1\n,\n      \n# simulation resolution\n\n    \nsim_time\n:\n \n1000.\n,\n      \n# total simulation time (often not required)\n\n    \ntransient_t\n:\n \n0.\n,\n      \n# transient time \n\n    \ndata_prefix\n:\n \ndata_label\n,\n\n    \ndata_path\n:\n \npaths\n[\nsystem_name\n][\ndata_path\n],\n\n    \nmpl_path\n:\n \npaths\n[\nsystem_name\n][\nmatplotlib_rc\n],\n\n    \noverwrite_files\n:\n \nTrue\n,\n\n    \nprint_time\n:\n \n(\nsystem_name\n \n==\n \nlocal\n),\n\n    \nrng_seeds\n:\n \nrange\n(\nmsd\n \n+\n \nN_vp\n \n+\n \n1\n,\n \nmsd\n \n+\n \n2\n \n*\n \nN_vp\n \n+\n \n1\n),\n\n    \ngrng_seed\n:\n \nmsd\n \n+\n \nN_vp\n,\n\n    \ntotal_num_virtual_procs\n:\n \nN_vp\n,\n\n    \nlocal_num_threads\n:\n \n16\n,\n\n    \nnp_seed\n:\n \nnp_seed\n,\n\n\n    \nsystem\n:\n \n{\n\n        \nlocal\n:\n \n(\nsystem_name\n \n==\n \nlocal\n),\n\n        \nsystem_label\n:\n \nsystem_name\n,\n\n        \nqueueing_system\n:\n \npaths\n[\nsystem_name\n][\nqueueing_system\n],\n\n        \njdf_template\n:\n \npaths\n[\nsystem_name\n][\njdf_template\n],\n\n        \nremote_directory\n:\n \npaths\n[\nsystem_name\n][\nremote_directory\n],\n\n        \njdf_fields\n:\n \n{\n{{ script_folder }}\n:\n \n,\n\n                       \n{{ nodes }}\n:\n \nstr\n(\nsystem_pars\n[\nnodes\n]),\n\n                       \n{{ ppn }}\n:\n \nstr\n(\nsystem_pars\n[\nppn\n]),\n\n                       \n{{ mem }}\n:\n \nstr\n(\nsystem_pars\n[\nmem\n]),\n\n                       \n{{ walltime }}\n:\n \nsystem_pars\n[\nwalltime\n],\n\n                       \n{{ queue }}\n:\n \nsystem_pars\n[\nqueue\n],\n\n                       \n{{ computation_script }}\n:\n \n}}})\n\n\n\n\n\n\nIf correctly specified, these parameters can be used during the initial setup of the main simulations:\n\n\nset_global_rcParams\n(\nparameter_set\n.\nkernel_pars\n[\nmpl_path\n])\n\n\nnp\n.\nrandom\n.\nseed\n(\nparameter_set\n.\nkernel_pars\n[\nnp_seed\n])\n\n\nnest\n.\nSetKernelStatus\n(\nextract_nestvalid_dict\n(\nkernel_pars\n.\nas_dict\n(),\n \nparam_type\n=\nkernel\n))\n\n\n\n\n\n\nNeuron\n\n\nNeuron model parameters, must strictly abide by the naming conventions of the NEST model requested. For example:\n\n\nneuron_pars\n \n=\n \n{\n\n    \nneuron_population_name\n:\n \n{\n   \n# \n\n        \nmodel\n:\n \niaf_psc_exp\n,\n\n        \nC_m\n:\n \n250.0\n,\n\n        \nE_L\n:\n \n0.0\n,\n\n        \nV_reset\n:\n \n0.0\n,\n\n        \nV_th\n:\n \n15.\n,\n\n        \nt_ref\n:\n \n2.\n,\n\n        \ntau_syn_ex\n:\n \n2.\n,\n\n        \ntau_syn_in\n:\n \n2.\n,\n\n        \ntau_m\n:\n \n20.\n}}\n\n\n\n\n\n\nTypically the neuron parameters are only used within the parameters file, as they will be placed\nin the network parameter dictionary, where the code will use them.\n\n\nNetwork\n\n\nNetwork parameters, specifying the composition, topology and which variables to record\nfrom the multiple populations:\n\n\nnet_pars\n \n=\n \n{\n\n    \nn_populations\n:\n \n2\n,\n         \n# total number of populations\n\n    \npop_names\n:\n \n[\nE\n,\n \nI\n],\n    \n# names for each population, here \nE\n for excitatory and \nI\n for inhibitory\n\n    \nn_neurons\n:\n \n[\n8000\n,\n \n2000\n],\n  \n# number of neurons in each population\n\n    \nneuron_pars\n:\n \n[\n\n            \nneuron_pars\n[\nE\n],\n   \n# neuron parameters for population name \nE\n \n\n            \nneuron_pars\n[\nI\n]],\n  \n# neuron parameters for population name \nI\n\n    \nrandomize_neuron_pars\n:\n \n[\n  \n# randomize certain parameters if necessary\n\n            \n{\nV_m\n:\n \n(\nnp\n.\nrandom\n.\nuniform\n,\n \n{\nlow\n:\n \n0.0\n,\n \nhigh\n:\n \n15.\n})},\n  \n            \n{\nV_m\n:\n \n(\nnp\n.\nrandom\n.\nuniform\n,\n \n{\nlow\n:\n \n0.0\n,\n \nhigh\n:\n \n15.\n})}],\n \n    \ntopology\n:\n \n[\nFalse\n,\n \nFalse\n],\n     \n# does the network have topology? True or False\n\n    \ntopology_dict\n:\n \n[\nNone\n,\n \nNone\n],\n  \n# dictionary with topology parameters, \n\n                                    \n# if topology is set to True for the population \n\n    \nrecord_spikes\n:\n \n[\nTrue\n,\n \nTrue\n],\n  \n# whether to record spikes for each population\n\n    \nspike_device_pars\n:\n \n[\n          \n# parameters for spike recording devices\n\n            \ncopy_dict\n(\nrec_devices\n,\n\n                    \n{\nmodel\n:\n \nspike_detector\n,\n\n                     \nrecord_to\n:\n \n[\nmemory\n],\n\n                     \nlabel\n:\n \n}),\n\n            \ncopy_dict\n(\nrec_devices\n,\n\n                    \n{\nmodel\n:\n \nspike_detector\n,\n\n                     \nrecord_to\n:\n \n[\nmemory\n],\n\n                     \nlabel\n:\n \n})],\n\n    \nrecord_analogs\n:\n \n[\nFalse\n,\n \nFalse\n],\n   \n# whether to record analog data for each population\n\n    \nanalog_device_pars\n:\n \n[\nNone\n,\n \nNone\n]}\n \n# parameters for analog devices\n\n\n\n\n\n\nNote that the dimensionality of all the list parameters has to be equal to \nn_populations\n. \n\n\nConnection\n\n\nConnectivity parameters, specifying the composition, topology and connectivity of\nthe multiple populations:\n\n\nconnection_pars\n \n=\n \n{\n\n    \n# [int] - total number of connections to establish\n\n    \nn_synapse_types\n:\n \n4\n,\n\n\n     \n# [list of tuples] - each tuple corresponds to 1 connection and \n\n     \n# has the form (tget_pop_label, src_pop_label)\n\n    \nsynapse_types\n:\n \n[(\nE\n,\n \nE\n),\n \n(\nE\n,\n \nI\n),\n \n(\nI\n,\n \nE\n),\n \n(\nI\n,\n \nI\n)],\n\n\n    \n# [list of str] - optional, additional names of the synapse models,\n\n    \n# useful is multiple synapses with different properties are derived \n\n    \n# from the same NEST model \n\n    \nsynapse_names\n:\n \n[\nEE\n,\n \nEI\n,\n \nIE\n,\n \nII\n],\n\n\n    \n# [list of bool] - whether synaptic connections are \n\n    \n# established relying on nest.topology module\n\n    \ntopology_dependent\n:[\nFalse\n,\n \nFalse\n,\n \nFalse\n,\n \nFalse\n],\n\n\n    \n# [list of str] - names of the synapse models to realize on each synapse type\n\n    \nmodels\n:\n \n[\nstatic_synapse\n,\n \nstatic_synapse\n,\n \nstatic_synapse\n,\n \nstatic_synapse\n],\n  \n\n    \n# [list of dict] - each entry in the list contains the synapse\n\n    \n# dictionary (if necessary) for the corresponding synapse model\n\n    \nmodel_pars\n:\n \n[\nsynapse_pars_dict\n,\n \nsynapse_pars_dict\n,\n \n                   \nsynapse_pars_dict\n,\n \nsynapse_pars_dict\n],\n\n\n    \n# [list of dict] - weight distribution parameters (in NEST format)\n\n    \nweight_dist\n:\n \n[\ncommon_syn_specs\n[\nweight\n],\n \ncommon_syn_specs\n[\nweight\n],\n \n                    \ncommon_syn_specs\n[\nweight\n],\n \ncommon_syn_specs\n[\nweight\n]],\n\n\n    \n# Provide an externally specified connectivity matrix if\n\n    \n# pre-computed weights matrices are provided, delays also need \n\n    \n# to be pre-specified, as an array with the same dimensions as W, \n\n    \n# with delay values on each corresponding entry. Alternatively, \n\n    \n# if all delays are the same, just provide a single number.\n\n    \npre_computedW\n:\n \n[\nNone\n,\n \nNone\n,\n \nNone\n,\n \nNone\n],\n\n\n    \n# [list of dict] - delay distribution parameters (in NEST format)\n\n    \ndelay_dist\n:\n \n[\ncommon_syn_specs\n[\ndelay\n],\n \ncommon_syn_specs\n[\ndelay\n],\n\n                   \ncommon_syn_specs\n[\ndelay\n],\n \ncommon_syn_specs\n[\ndelay\n]],\n\n\n    \n# [list of dict] - for topological connections\n\n    \nconn_specs\n:\n \n[\nconn_specs\n,\n \nconn_specs\n,\n \nconn_specs\n,\n \nconn_specs\n],\n\n\n    \n# [list of dict] - \n\n    \nsyn_specs\n:\n \n[]\n\n\n\n\n\n\nYou can create new synapses with unique names by deriving from the existing NEST models, e.g., for defining two \n connections with different time constants of STDP window  \n\n\nconnection_pars\n \n=\n \n{\n\n    \n(\n...\n)\n\n    \nsynapse_types\n:\n \n[(\nE_1\n,\n \nI_1\n),\n \n(\nE_2\n,\n \nI_2\n)],\n\n    \nsynapse_names\n:\n \n[\nMySTDP_window_10\n,\n \nMySTDP_window_30\n],\n\n    \nmodels\n:\n        \n[\nstdp_synapse\n,\n \nstdp_synapse\n]\n \n# any NEST model to derive from \n\n    \nmodel_pars\n:\n    \n[{\ntau_plus\n:\n \n10.\n},\n \n{\ntau_plus\n:\n \n30.\n}]}\n  \n\n\n\n\n\nStimulus\n\n\nStimulus or task parameters:\n\n\nstim_pars\n \n=\n \n{\n\n        \nn_stim\n:\n \n10\n,\n               \n# number of stimuli\n\n        \nelements\n:\n \n[\nA\n,\n \nB\n,\n      \n#  \n\n                     \nC\n,\n \n...\n],\n\n        \ngrammar\n:\n \nNone\n,\n            \n#!!\n\n        \nfull_set_length\n:\n \nint\n(\nT\n \n+\n \nT_discard\n),\n  \n# total samples\n\n        \ntransient_set_length\n:\n \nint\n(\nT_discard\n),\n \n# size of transient set (will be discarded)\n\n        \ntrain_set_length\n:\n \nint\n(\n0.8\n \n*\n \nT\n),\n       \n# size of training set\n\n        \ntest_set_length\n:\n \nint\n(\n0.2\n \n*\n \nT\n)}\n        \n# size of test set\n\n\n\n\n\n\nTo generate a stimulus set:\n\n\nstim_set\n \n=\n \nStimulusSet\n()\n\n\nstim_set\n.\ngenerate_datasets\n(\nstim_pars\n)\n\n\n\n\n\n\nInput\n\n\nSpecifies the stimulus transduction and/or the input signal properties:\n\n\ninput_pars\n \n=\n \n{\n\n    \nsignal\n:\n \n{\n\n        \n# Dimensionality of the signal\n\n        \nN\n:\n \n3\n,\n \n\n        \n# Duration of each stimulus presentation. \n\n        \n# Various settings are allowed:\n\n        \n#   - List of n_trials elements whose values correspond to the \n\n        \n#     duration of 1 stimulus presentation\n\n        \n#   - List with one single element (uniform durations)\n\n        \n#   - Tuple of (function, function parameters) specifying \n\n        \n#     distributions for these values, \n\n        \n#   - List of N lists of any of the formats specified... (*)\n\n        \ndurations\n:\n \n[(\nnp\n.\nrandom\n.\nuniform\n,\n \n{\nlow\n:\n \n500.\n,\n \nhigh\n:\n \n500.\n,\n \nsize\n:\n \nn_trials\n})],\n\n\n        \n# Inter-stimulus intervals - same settings as \ndurations\n.\n\n        \ni_stim_i\n:\n \n[(\nnp\n.\nrandom\n.\nuniform\n,\n \n{\nlow\n:\n \n0.\n,\n \nhigh\n:\n \n0.\n,\n \nsize\n:\n \nn_trials\n-\n1\n})],\n\n\n        \n# input mask - implemented options:\n\n        \n#   box({}), exp({\ntau\n}), double_exp({\ntau_1\n,\ntau_2\n}), gauss({\nmu\n, \nsigma\n})\n\n        \nkernel\n:\n \n(\nbox\n,\n \n{}),\n  \n\n        \nstart_time\n:\n \n0.\n,\n                   \n# global signal onset time\n\n        \nstop_time\n:\n \nsys\n.\nfloat_info\n.\nmax\n,\n    \n# global signal offset time\n\n\n        \n# maximum signal amplitude - as in durations and i_stim_i,\n\n        \n# can be a list of values, or a function with parameters\n\n        \nmax_amplitude\n:\n \n[(\nnp\n.\nrandom\n.\nuniform\n,\n \n{\nlow\n:\n \n10.\n,\n \nhigh\n:\n \n100.\n,\n \nsize\n:\n \nn_trials\n})],\n\n\n        \nmin_amplitude\n:\n \n0.\n,\n    \n# minimum amplitude - will be added to the signal\n\n        \nresolution\n:\n \n1.\n        \n# temporal resolution\n\n        \n},\n\n\n    \nnoise\n:\n \n{\n\n        \n# Dimensionality of the noise component (common or \n\n        \n# multiple independent noise sources)\n\n        \nN\n:\n \n3\n,\n \n\n        \n# [list] - Type of noise:\n\n        \n#  - Either a string for \nOU\n, \nGWN\n\n        \n#  - or a function, e.g. np.random.uniform\n\n        \nnoise_source\n:\n \n[\nGWN\n],\n\n\n        \n# [dict] Parameters (specific for each type of noise):\n\n        \n# - \nOU\n -\n {\ntau\n, \nsigma\n, \ny0\n}\n\n        \n# - \nGWN\n -\n {\namplitude\n, \nmean\n, \nstd\n}\n\n        \n# - function parameters dictionary (see function documentation)\n\n        \nnoise_pars\n:\n \n{\namplitude\n:\n \n1.\n,\n \nmean\n:\n \n1.\n,\n \nstd\n:\n \n0.1\n},\n\n\n        \nrectify\n:\n \nTrue\n,\n    \n# [bool] - rectify noise component\n\n\n        \n# global onset time (single value), \n\n        \n# or local onset times if multiple instances are required (list)\n\n        \nstart_time\n:\n \n0.\n,\n   \n\n        \n# global offset time (single value), or local offset\n\n        \n# times, if multiple instances are required\n\n        \nstop_time\n:\n \nsys\n.\nfloat_info\n.\nmax\n,\n    \n\n        \n# signal resolution (dt)\n\n        \nresolution\n:\n \n1.\n \n}}\n          \n\n\n\n\n\nNote:\n the chosen specifications of \ndurations\n, \ni_stim_i\n and \nmax_amplitude\n\nmust be consistent, i.e., if \ndurations\n is provided as a single element list, the same format must\nbe applied to \ni_stim_i\n and \nmax_amplitude\n. (test)\n\n\ninputs\n \n=\n \nInputSignalSet\n(\nparameter_set\n,\n \nstim_set\n,\n \nonline\n=\nonline\n)\n\n\ninputs\n.\ngenerate_datasets\n(\nstim_set\n)\n\n\n\n\n\n\nEncoding\n\n\nencoding_pars\n \n=\n \n{\n\n    \nencoder\n:\n \n{\n\n        \nN\n:\n \n1\n,\n                         \n# number of encoder objects\n\n        \nlabels\n:\n \n[\nparrot_exc\n],\n       \n# unique names for each encoder\n\n        \nmodels\n:\n \n[\nparrot_neuron\n],\n    \n# encoder model\n\n        \nmodel_pars\n:\n \n[\nNone\n],\n           \n# if override default model parameters\n\n        \nn_neurons\n:\n \n[\n200\n],\n             \n# dimensionality of the encoder\n\n                                        \n# (here 200 parrot neurons will be created)\n\n        \nneuron_pars\n:\n \n[{\nmodel\n:\n \nparrot_neuron\n}],\n\n        \ntopology\n:\n \n[\nFalse\n],\n            \n# use topology?\n\n        \ntopology_dict\n:\n \n[\nNone\n],\n        \n# topology parameters?\n\n        \nrecord_spikes\n:\n \n[\nFalse\n],\n       \n# whether to record spikes for the encoder\n\n        \nspike_device_pars\n:\n \n[{}],\n      \n# spike recorder parameters\n\n        \nrecord_analogs\n:\n \n[\nFalse\n],\n      \n# whether to record analog variables\n\n        \nanalog_device_pars\n:\n \n[{}]},\n    \n# analog recorder parameters\n\n\n    \ngenerator\n:\n \n{\n\n        \nN\n:\n \n1\n,\n                         \n# number of generator objects\n\n        \nlabels\n:\n \n[\ninh_generator\n],\n    \n# unique name for each generator\n\n\n        \n# NEST generator model, the following are possible\n\n        \n#   (spike_generator, inh_poisson_generator, poisson_generator, \n\n        \n#    step_current_generator...)\n\n        \nmodels\n:\n \n[\ninh_poisson_generator\n],\n\n\n        \n# override default generator model parameters  \n\n        \nmodel_pars\n:\n \n[{\nstart\n:\n \n0.\n,\n \nstop\n:\n \nsys\n.\nfloat_info\n.\nmax\n,\n \norigin\n:\n \n0.\n},],\n\n\n        \ntopology\n:\n \n[\nFalse\n],\n            \n# use topology?\n\n        \ntopology_pars\n:\n \n[\nNone\n]},\n       \n# topology parameters?\n\n\n    \nconnectivity\n:\n \n{\n\n        \nsynapse_name\n:\n \n[\nstatic_synapse\n,\n \nstatic_synapse\n],\n\n        \nconnections\n:\n \n[(\nparrot_exc\n,\n \ninh_generator\n),\n \n# name of generator must match\n\n                        \n(\npopulation_1\n,\n \nparrot_exc\n)],\n\n        \ntopology_dependent\n:\n \n[\nFalse\n,\n \nFalse\n],\n\n        \nconn_specs\n:\n \n[{\nrule\n:\n \nall_to_all\n},\n \n{\nrule\n:\n \nall_to_all\n}],\n\n        \nsyn_specs\n:\n \n[{},\n \n{}],\n\n        \nmodels\n:\n \n[\nstatic_synapse\n,\n \nstatic_synapse\n],\n\n        \nmodel_pars\n:\n \n[{},\n \n{}],\n\n        \nweight_dist\n:\n \n[\n1.\n,\n \n20.\n],\n\n        \ndelay_dist\n:\n \n[\nencoder_delay\n,\n \nencoder_delay\n],\n\n        \npreset_W\n:\n \n[\nNone\n,\n \nNone\n]}}\n\n\n\n\n\n\nWhen creating the encoding layer, you can pass a signal as input for the generators, and you can choose to \n precompute the output of the encoders (\nonline=False\n) or generate it on-the-fly during simulation (\nonline=True\n):  \n\n\nenc_layer\n \n=\n \nEncodingLayer\n(\nparameter_set\n.\nencoding_pars\n,\n \nsignal\n=\ninputs\n.\nfull_set_signal\n,\n \nonline\n=\nTrue\n)\n\n\nenc_layer\n.\nconnect\n(\nparameter_set\n.\nencoding_pars\n,\n \nnet\n)\n\n\n\n\n\n\nDecoding\n\n\ndecoders\n \n=\n \ndict\n(\n\n    \ndecoded_population\n=\n[\nE\n,\n \nE\n,\n \n[\nE\n,\n \nI\n],\n \n[\nE\n,\n \nI\n],\n \nI\n,\n \nI\n],\n\n    \nstate_variable\n=\n[\nV_m\n,\n \nspikes\n,\n \nV_m\n,\n \nspikes\n,\n \nV_m\n,\n \nspikes\n],\n\n    \nfilter_time\n=\nfilter_tau\n,\n\n    \nreadouts\n=\nreadout_labels\n,\n\n    \nreadout_algorithms\n=\n[\nridge\n,\n \nridge\n,\n \nridge\n,\n \nridge\n,\n \nridge\n,\n \nridge\n],\n\n    \nglobal_sampling_times\n=\nstate_sampling\n,\n\n\n)\n\n\n\n\n\n\nnet\n.\nconnect_decoders\n(\nparameter_set\n.\ndecoding_pars\n)\n\n\nenc_layer\n.\nconnect_decoders\n(\nparameter_set\n.\nencoding_pars\n.\ninput_decoder\n)\n\n\n\n\n\n\nAnalysis\n\n\n-\n\n\nParameter presets\n\n\nFor convenience, to reduce the length and complexity of the parameter files and the likelihood of\naccidentally changing the values of fixed, commonly used parameter sets, we typically include a set of\npreset dictionaries and simple functions to retrieve them and to simplify the construction of parameters\nfiles (see examples and upcoming project files).", 
            "title": "Parameters file and parameters module"
        }, 
        {
            "location": "/parameters/#parameter-range-declarations-and-build-function", 
            "text": "NMSAT allows the definition of ranges for the values of various parameters of choice via the  parameter_range  dictionary,\nin order simplify running the same experiment when only some parameter values change:  parameter_range   =   { \n     max_current :   [ 800. ]  }  def   build_parameters ( max_current ): \n     ...  \n\nIn this case, only one simulation will be executed where  max_current = 800. . However, the following code   parameter_range   =   { \n     max_current :   [ 800. ,   1200. ], \n     total_time :   [ 1000. ]  }  def   build_parameters ( max_current ,   total_time ): \n     ...   will result in 2 separate runs, one for each parameter combination:   max_current = 800., total_time = 1000.  max_current = 1200., total_time = 1000.   The  build_parameters(...)  function is required in every parameter file. If the  parameter_range  dictionary is not \nempty, its keys (more precisely equivalent variable names) must be passed as arguments to the  build_parameters  function.", 
            "title": "Parameter range declarations and build function"
        }, 
        {
            "location": "/parameters/#parameter-types", 
            "text": "The returned value of the  build_parameters(...)  function is a dictionary of  ParameterSets , containing all the\nnecessary types of parameters to be used by the main experiment. These parameters defined in the function are themselves ParameterSets  dictionaries:  return   dict ([( kernel_pars ,     kernel_pars ), \n              ( neuron_pars ,     neuron_pars ), \n              ( net_pars ,        net_pars ), \n              ( encoding_pars ,   encoding_pars )])   Each key in the returned dictionary must match the name of the variable. Acceptable types (with examples of use) are:", 
            "title": "Parameter types"
        }, 
        {
            "location": "/parameters/#kernel", 
            "text": "Specifies all relevant system and simulation parameters.  kernel_pars   =   ParameterSet ({ \n     resolution :   0.1 ,        # simulation resolution \n     sim_time :   1000. ,        # total simulation time (often not required) \n     transient_t :   0. ,        # transient time  \n     data_prefix :   data_label , \n     data_path :   paths [ system_name ][ data_path ], \n     mpl_path :   paths [ system_name ][ matplotlib_rc ], \n     overwrite_files :   True , \n     print_time :   ( system_name   ==   local ), \n     rng_seeds :   range ( msd   +   N_vp   +   1 ,   msd   +   2   *   N_vp   +   1 ), \n     grng_seed :   msd   +   N_vp , \n     total_num_virtual_procs :   N_vp , \n     local_num_threads :   16 , \n     np_seed :   np_seed , \n\n     system :   { \n         local :   ( system_name   ==   local ), \n         system_label :   system_name , \n         queueing_system :   paths [ system_name ][ queueing_system ], \n         jdf_template :   paths [ system_name ][ jdf_template ], \n         remote_directory :   paths [ system_name ][ remote_directory ], \n         jdf_fields :   { {{ script_folder }} :   , \n                        {{ nodes }} :   str ( system_pars [ nodes ]), \n                        {{ ppn }} :   str ( system_pars [ ppn ]), \n                        {{ mem }} :   str ( system_pars [ mem ]), \n                        {{ walltime }} :   system_pars [ walltime ], \n                        {{ queue }} :   system_pars [ queue ], \n                        {{ computation_script }} :   }}})   If correctly specified, these parameters can be used during the initial setup of the main simulations:  set_global_rcParams ( parameter_set . kernel_pars [ mpl_path ])  np . random . seed ( parameter_set . kernel_pars [ np_seed ])  nest . SetKernelStatus ( extract_nestvalid_dict ( kernel_pars . as_dict (),   param_type = kernel ))", 
            "title": "Kernel"
        }, 
        {
            "location": "/parameters/#neuron", 
            "text": "Neuron model parameters, must strictly abide by the naming conventions of the NEST model requested. For example:  neuron_pars   =   { \n     neuron_population_name :   {     #  \n         model :   iaf_psc_exp , \n         C_m :   250.0 , \n         E_L :   0.0 , \n         V_reset :   0.0 , \n         V_th :   15. , \n         t_ref :   2. , \n         tau_syn_ex :   2. , \n         tau_syn_in :   2. , \n         tau_m :   20. }}   Typically the neuron parameters are only used within the parameters file, as they will be placed\nin the network parameter dictionary, where the code will use them.", 
            "title": "Neuron"
        }, 
        {
            "location": "/parameters/#network", 
            "text": "Network parameters, specifying the composition, topology and which variables to record\nfrom the multiple populations:  net_pars   =   { \n     n_populations :   2 ,           # total number of populations \n     pop_names :   [ E ,   I ],      # names for each population, here  E  for excitatory and  I  for inhibitory \n     n_neurons :   [ 8000 ,   2000 ],    # number of neurons in each population \n     neuron_pars :   [ \n             neuron_pars [ E ],     # neuron parameters for population name  E   \n             neuron_pars [ I ]],    # neuron parameters for population name  I \n     randomize_neuron_pars :   [    # randomize certain parameters if necessary \n             { V_m :   ( np . random . uniform ,   { low :   0.0 ,   high :   15. })},   \n             { V_m :   ( np . random . uniform ,   { low :   0.0 ,   high :   15. })}],  \n     topology :   [ False ,   False ],       # does the network have topology? True or False \n     topology_dict :   [ None ,   None ],    # dictionary with topology parameters,  \n                                     # if topology is set to True for the population  \n     record_spikes :   [ True ,   True ],    # whether to record spikes for each population \n     spike_device_pars :   [            # parameters for spike recording devices \n             copy_dict ( rec_devices , \n                     { model :   spike_detector , \n                      record_to :   [ memory ], \n                      label :   }), \n             copy_dict ( rec_devices , \n                     { model :   spike_detector , \n                      record_to :   [ memory ], \n                      label :   })], \n     record_analogs :   [ False ,   False ],     # whether to record analog data for each population \n     analog_device_pars :   [ None ,   None ]}   # parameters for analog devices   Note that the dimensionality of all the list parameters has to be equal to  n_populations .", 
            "title": "Network"
        }, 
        {
            "location": "/parameters/#connection", 
            "text": "Connectivity parameters, specifying the composition, topology and connectivity of\nthe multiple populations:  connection_pars   =   { \n     # [int] - total number of connections to establish \n     n_synapse_types :   4 , \n\n      # [list of tuples] - each tuple corresponds to 1 connection and  \n      # has the form (tget_pop_label, src_pop_label) \n     synapse_types :   [( E ,   E ),   ( E ,   I ),   ( I ,   E ),   ( I ,   I )], \n\n     # [list of str] - optional, additional names of the synapse models, \n     # useful is multiple synapses with different properties are derived  \n     # from the same NEST model  \n     synapse_names :   [ EE ,   EI ,   IE ,   II ], \n\n     # [list of bool] - whether synaptic connections are  \n     # established relying on nest.topology module \n     topology_dependent :[ False ,   False ,   False ,   False ], \n\n     # [list of str] - names of the synapse models to realize on each synapse type \n     models :   [ static_synapse ,   static_synapse ,   static_synapse ,   static_synapse ],   \n\n     # [list of dict] - each entry in the list contains the synapse \n     # dictionary (if necessary) for the corresponding synapse model \n     model_pars :   [ synapse_pars_dict ,   synapse_pars_dict ,  \n                    synapse_pars_dict ,   synapse_pars_dict ], \n\n     # [list of dict] - weight distribution parameters (in NEST format) \n     weight_dist :   [ common_syn_specs [ weight ],   common_syn_specs [ weight ],  \n                     common_syn_specs [ weight ],   common_syn_specs [ weight ]], \n\n     # Provide an externally specified connectivity matrix if \n     # pre-computed weights matrices are provided, delays also need  \n     # to be pre-specified, as an array with the same dimensions as W,  \n     # with delay values on each corresponding entry. Alternatively,  \n     # if all delays are the same, just provide a single number. \n     pre_computedW :   [ None ,   None ,   None ,   None ], \n\n     # [list of dict] - delay distribution parameters (in NEST format) \n     delay_dist :   [ common_syn_specs [ delay ],   common_syn_specs [ delay ], \n                    common_syn_specs [ delay ],   common_syn_specs [ delay ]], \n\n     # [list of dict] - for topological connections \n     conn_specs :   [ conn_specs ,   conn_specs ,   conn_specs ,   conn_specs ], \n\n     # [list of dict] -  \n     syn_specs :   []   You can create new synapses with unique names by deriving from the existing NEST models, e.g., for defining two \n connections with different time constants of STDP window    connection_pars   =   { \n     ( ... ) \n     synapse_types :   [( E_1 ,   I_1 ),   ( E_2 ,   I_2 )], \n     synapse_names :   [ MySTDP_window_10 ,   MySTDP_window_30 ], \n     models :          [ stdp_synapse ,   stdp_synapse ]   # any NEST model to derive from  \n     model_pars :      [{ tau_plus :   10. },   { tau_plus :   30. }]}", 
            "title": "Connection"
        }, 
        {
            "location": "/parameters/#stimulus", 
            "text": "Stimulus or task parameters:  stim_pars   =   { \n         n_stim :   10 ,                 # number of stimuli \n         elements :   [ A ,   B ,        #   \n                      C ,   ... ], \n         grammar :   None ,              #!! \n         full_set_length :   int ( T   +   T_discard ),    # total samples \n         transient_set_length :   int ( T_discard ),   # size of transient set (will be discarded) \n         train_set_length :   int ( 0.8   *   T ),         # size of training set \n         test_set_length :   int ( 0.2   *   T )}          # size of test set   To generate a stimulus set:  stim_set   =   StimulusSet ()  stim_set . generate_datasets ( stim_pars )", 
            "title": "Stimulus"
        }, 
        {
            "location": "/parameters/#input", 
            "text": "Specifies the stimulus transduction and/or the input signal properties:  input_pars   =   { \n     signal :   { \n         # Dimensionality of the signal \n         N :   3 ,  \n\n         # Duration of each stimulus presentation.  \n         # Various settings are allowed: \n         #   - List of n_trials elements whose values correspond to the  \n         #     duration of 1 stimulus presentation \n         #   - List with one single element (uniform durations) \n         #   - Tuple of (function, function parameters) specifying  \n         #     distributions for these values,  \n         #   - List of N lists of any of the formats specified... (*) \n         durations :   [( np . random . uniform ,   { low :   500. ,   high :   500. ,   size :   n_trials })], \n\n         # Inter-stimulus intervals - same settings as  durations . \n         i_stim_i :   [( np . random . uniform ,   { low :   0. ,   high :   0. ,   size :   n_trials - 1 })], \n\n         # input mask - implemented options: \n         #   box({}), exp({ tau }), double_exp({ tau_1 , tau_2 }), gauss({ mu ,  sigma }) \n         kernel :   ( box ,   {}),   \n\n         start_time :   0. ,                     # global signal onset time \n         stop_time :   sys . float_info . max ,      # global signal offset time \n\n         # maximum signal amplitude - as in durations and i_stim_i, \n         # can be a list of values, or a function with parameters \n         max_amplitude :   [( np . random . uniform ,   { low :   10. ,   high :   100. ,   size :   n_trials })], \n\n         min_amplitude :   0. ,      # minimum amplitude - will be added to the signal \n         resolution :   1.          # temporal resolution \n         }, \n\n     noise :   { \n         # Dimensionality of the noise component (common or  \n         # multiple independent noise sources) \n         N :   3 ,  \n\n         # [list] - Type of noise: \n         #  - Either a string for  OU ,  GWN \n         #  - or a function, e.g. np.random.uniform \n         noise_source :   [ GWN ], \n\n         # [dict] Parameters (specific for each type of noise): \n         # -  OU  -  { tau ,  sigma ,  y0 } \n         # -  GWN  -  { amplitude ,  mean ,  std } \n         # - function parameters dictionary (see function documentation) \n         noise_pars :   { amplitude :   1. ,   mean :   1. ,   std :   0.1 }, \n\n         rectify :   True ,      # [bool] - rectify noise component \n\n         # global onset time (single value),  \n         # or local onset times if multiple instances are required (list) \n         start_time :   0. ,    \n\n         # global offset time (single value), or local offset \n         # times, if multiple instances are required \n         stop_time :   sys . float_info . max ,     \n\n         # signal resolution (dt) \n         resolution :   1.   }}             Note:  the chosen specifications of  durations ,  i_stim_i  and  max_amplitude \nmust be consistent, i.e., if  durations  is provided as a single element list, the same format must\nbe applied to  i_stim_i  and  max_amplitude . (test)  inputs   =   InputSignalSet ( parameter_set ,   stim_set ,   online = online )  inputs . generate_datasets ( stim_set )", 
            "title": "Input"
        }, 
        {
            "location": "/parameters/#encoding", 
            "text": "encoding_pars   =   { \n     encoder :   { \n         N :   1 ,                           # number of encoder objects \n         labels :   [ parrot_exc ],         # unique names for each encoder \n         models :   [ parrot_neuron ],      # encoder model \n         model_pars :   [ None ],             # if override default model parameters \n         n_neurons :   [ 200 ],               # dimensionality of the encoder \n                                         # (here 200 parrot neurons will be created) \n         neuron_pars :   [{ model :   parrot_neuron }], \n         topology :   [ False ],              # use topology? \n         topology_dict :   [ None ],          # topology parameters? \n         record_spikes :   [ False ],         # whether to record spikes for the encoder \n         spike_device_pars :   [{}],        # spike recorder parameters \n         record_analogs :   [ False ],        # whether to record analog variables \n         analog_device_pars :   [{}]},      # analog recorder parameters \n\n     generator :   { \n         N :   1 ,                           # number of generator objects \n         labels :   [ inh_generator ],      # unique name for each generator \n\n         # NEST generator model, the following are possible \n         #   (spike_generator, inh_poisson_generator, poisson_generator,  \n         #    step_current_generator...) \n         models :   [ inh_poisson_generator ], \n\n         # override default generator model parameters   \n         model_pars :   [{ start :   0. ,   stop :   sys . float_info . max ,   origin :   0. },], \n\n         topology :   [ False ],              # use topology? \n         topology_pars :   [ None ]},         # topology parameters? \n\n     connectivity :   { \n         synapse_name :   [ static_synapse ,   static_synapse ], \n         connections :   [( parrot_exc ,   inh_generator ),   # name of generator must match \n                         ( population_1 ,   parrot_exc )], \n         topology_dependent :   [ False ,   False ], \n         conn_specs :   [{ rule :   all_to_all },   { rule :   all_to_all }], \n         syn_specs :   [{},   {}], \n         models :   [ static_synapse ,   static_synapse ], \n         model_pars :   [{},   {}], \n         weight_dist :   [ 1. ,   20. ], \n         delay_dist :   [ encoder_delay ,   encoder_delay ], \n         preset_W :   [ None ,   None ]}}   When creating the encoding layer, you can pass a signal as input for the generators, and you can choose to \n precompute the output of the encoders ( online=False ) or generate it on-the-fly during simulation ( online=True ):    enc_layer   =   EncodingLayer ( parameter_set . encoding_pars ,   signal = inputs . full_set_signal ,   online = True )  enc_layer . connect ( parameter_set . encoding_pars ,   net )", 
            "title": "Encoding"
        }, 
        {
            "location": "/parameters/#decoding", 
            "text": "decoders   =   dict ( \n     decoded_population = [ E ,   E ,   [ E ,   I ],   [ E ,   I ],   I ,   I ], \n     state_variable = [ V_m ,   spikes ,   V_m ,   spikes ,   V_m ,   spikes ], \n     filter_time = filter_tau , \n     readouts = readout_labels , \n     readout_algorithms = [ ridge ,   ridge ,   ridge ,   ridge ,   ridge ,   ridge ], \n     global_sampling_times = state_sampling ,  )   net . connect_decoders ( parameter_set . decoding_pars )  enc_layer . connect_decoders ( parameter_set . encoding_pars . input_decoder )", 
            "title": "Decoding"
        }, 
        {
            "location": "/parameters/#analysis", 
            "text": "-", 
            "title": "Analysis"
        }, 
        {
            "location": "/parameters/#parameter-presets", 
            "text": "For convenience, to reduce the length and complexity of the parameter files and the likelihood of\naccidentally changing the values of fixed, commonly used parameter sets, we typically include a set of\npreset dictionaries and simple functions to retrieve them and to simplify the construction of parameters\nfiles (see examples and upcoming project files).", 
            "title": "Parameter presets"
        }, 
        {
            "location": "/input/", 
            "text": "The \ninput_architect.py\n module handles everything related to input stimuli and signals. It is\ndesigned to encompass a large variety of input stimuli / signals, patterned according to complex\nspecifications. However, at the moment, due to recent changes, not all variants have been tested.\nNone of the following components of the input construction process is strictly necessary. For example,\na signal can be generated using the signal_pars, without the need for a StimulusSet to be specified.\nThe main classes are:\n\n\n\n\nStimulusSet\n \u2013 hold and manipulate all the data pertaining to the input stimuli, labels, and\ncorresponding time series, can be divided into data sets (transient, train and test sets)\n\n\nInputSignalSet\n \u2013 container for all the relevant signals, divided into data sets (transient, train\nand test sets)\n\n\nInputSignal\n \u2013 Generate and store AnalogSignal object referring to the structured input\nsignal u(t)\n\n\nInputNoise\n \u2013 Generate and store AnalogSignal object referring to the noise signal", 
            "title": "Input specification and generation"
        }, 
        {
            "location": "/encoding/", 
            "text": "The EncodingLayer class wraps all the encoding process, involving the conversion of the continuous input signals. It\u2019s main constituents are:\n\n\n\n\nGenerator\n \u2013 consists of a NEST generator device (e.g. spike_generator, step_current_generator,\ninh_poisson_generator). Note that in the parameter specifications, N refers to the number of unique devices in the setup not the number of devices of a certain type (this is later acquired by the dimensionality of the input signal to be encoded - 1 unique generator device per input dimension)\n\n\nEncoder\n \u2013 consists of a Population object containing a layer of spiking neurons or some other mechanism that converts the continuous input into spike trains to be fed to the network", 
            "title": "Encoding layer"
        }, 
        {
            "location": "/populations-and-networks/", 
            "text": "One of the core tasks in each experiment is to set up a network of neuronal populations to be simulated. In NMSAT, \n  individual neurons are grouped into homogeneous populations and stored in \nPopulation\n objects. These, in turn, are\n  organized into a single \nNetwork\n object that acts as a wrapper for all populations to allow their efficient handling. \n\n\nBoth classes are defined in the \nnet_architect.py\n module.  \n\n\nPopulations\n\n\nPopulation\n objects are used to handle each of the simulated neuronal populations and contain\n  their parameters, such as name (unique among all populations), size, topology, etc. They also define what recording devices \n  (\nspike_detector, multimeter\n) should be connected to the populations, store the spiking and analog activities \n  in \nSpikeLists\n and \nAnalogSignalLists\n, and keep track of the attached \ndecoding layer\n.   \n\n\nNetwork\n\n\nGenerally there is only one \nNetwork\n object in each experiment, which keeps a list with all the populations building the \n  network, along with their connectivity properties. It provides routines for creating and connecting the populations, \n  attaching the recording devices and decoders, and extracting the activity from the simulator after termination. It is \n  also possible to merge different populations to create larger, heterogeneous clusters within the network. \n\n\nCreating populations and networks\n\n\nThree parameter dictionaries are used to define populations and networks (for detailed description follow the links):\n\n\n\n\nneuron_pars\n - neuron models and their parameters \n\n\nnet_pars\n - specifies the composition, topology and which variables to record\nfrom the multiple populations. Note that there is no separate dictionary for the individual populations, they are all\ndefined in the lists of this dictionary.\n\n\nconnection_pars\n - parameter set defining connections among populations and their synaptic\nproperties (synapse model, weight distributions, delays, etc.). \n\n\n\n\nIf these parameters are all correctly set, generating a network and initializing all connections is as simple as:\n\n\n# create Network object\n\n\nnet\n \n=\n \nNetwork\n(\nparameter_set\n.\nnet_pars\n)\n \n\n\n# optional, example for merging two populations\n\n\n# net.merge_subpopulations([net.populations[0], net.populations[1]], name=\nEI\n) \n\n\n\n# connect populations, for complex connectivity schemes it is worth setting \n\n\n# `progress=True` to accompany the connection progress\n\n\nnet\n.\nconnect_populations\n(\nparameter_set\n.\nconnection_pars\n,\n \nprogress\n=\nFalse\n)\n\n\n\n# attach devices\n\n\nnet\n.\nconnect_devices\n()\n\n\n\n# connect the decoders\n\n\nnet\n.\nconnect_decoders\n(\nparameter_set\n.\ndecoding_pars\n)", 
            "title": "Populations and networks"
        }, 
        {
            "location": "/populations-and-networks/#populations", 
            "text": "Population  objects are used to handle each of the simulated neuronal populations and contain\n  their parameters, such as name (unique among all populations), size, topology, etc. They also define what recording devices \n  ( spike_detector, multimeter ) should be connected to the populations, store the spiking and analog activities \n  in  SpikeLists  and  AnalogSignalLists , and keep track of the attached  decoding layer .", 
            "title": "Populations"
        }, 
        {
            "location": "/populations-and-networks/#network", 
            "text": "Generally there is only one  Network  object in each experiment, which keeps a list with all the populations building the \n  network, along with their connectivity properties. It provides routines for creating and connecting the populations, \n  attaching the recording devices and decoders, and extracting the activity from the simulator after termination. It is \n  also possible to merge different populations to create larger, heterogeneous clusters within the network.", 
            "title": "Network"
        }, 
        {
            "location": "/populations-and-networks/#creating-populations-and-networks", 
            "text": "Three parameter dictionaries are used to define populations and networks (for detailed description follow the links):   neuron_pars  - neuron models and their parameters   net_pars  - specifies the composition, topology and which variables to record\nfrom the multiple populations. Note that there is no separate dictionary for the individual populations, they are all\ndefined in the lists of this dictionary.  connection_pars  - parameter set defining connections among populations and their synaptic\nproperties (synapse model, weight distributions, delays, etc.).    If these parameters are all correctly set, generating a network and initializing all connections is as simple as:  # create Network object  net   =   Network ( parameter_set . net_pars )   # optional, example for merging two populations  # net.merge_subpopulations([net.populations[0], net.populations[1]], name= EI )   # connect populations, for complex connectivity schemes it is worth setting   # `progress=True` to accompany the connection progress  net . connect_populations ( parameter_set . connection_pars ,   progress = False )  # attach devices  net . connect_devices ()  # connect the decoders  net . connect_decoders ( parameter_set . decoding_pars )", 
            "title": "Creating populations and networks"
        }, 
        {
            "location": "/decoding/", 
            "text": "Specifying state variables\n\n\nIn the current implementation, one can simultaneously record and readout all relevant variables, for\ncomparison purposes (as long as they are recordable). To do so, we just specify which populations\nto read, and which variable to read from. This is done in the dictionary that is passed as argument to the decoding defaults (see below), namely the key variables \ndecoded_population\n and\n\nstate_variable\n.\n\n\nThese two variables need to be lists of equal length. A given decoded_population can be\nspecified as a sub-list, which means that we want to extract 1 state matrix from the combination of\nthe two referred populations (which are merged for this purpose). See example below.\n\n\nState sampling methods\n\n\nThe population responses to the stimuli can also be extracted in various different ways, by taking\nsamples of the state variable under consideration. In the current implementation this is simply done with the decoder variable global_sampling_times:\n\n\n\n\nOne-sample at the stimulus offset (default, t* ):\n\n\nglobal_sampling_times = None\n\n\none population state vector per stimulus\n\n\n\n\n\n\nMultiple samples taken at specific times (all stimuli must have the same duration):\n\n\nglobal_sampling_times is given as a list of np.array of times (from stimulus onset) - length N*\n\n\none population state vector per sampling time\n\n\nconstructs N* state matrices that will be independently readout\n\n\n\n\n\n\nSub-sampling responses at a fixed rate:\n\n\nglobal_sampling_times = 1/10 is given as a fraction (one sample every 10 steps, step size being the input resolution)\n\n\nconstructs one long state matrix corresponding to the full response (in the limit, if global_sampling_times = 1, this corresponds to the entire activity history, sampled at the input resolution)\n\n\nthe target is also downsampled to the same rate, implementing an approximation to a continuous readout.\n\n\n\n\n\n\n\n\nThese different methods are used for different purposes, to assess different features of the responses. See Examples. Note that in the current version only the first sampling method is fully implemented and tested.\n\n\nReadouts\n\n\nCurrently available algorithms are:\n\n\n\n\nDirect pseudo-inverse - \n'pinv'\n\n\nRidge Regression - \n'ridge'\n\n\nLogistic Regression - \n'logistic'\n\n\nPerceptron - \n'perceptron'\n\n\nLinear SVM - \n'svm-linear'\n\n\nNon-linear SVM (radial basis function) - \n'svm-rbf'\n\n\nElastic Net - \n'elastic'\n\n\nBayesian Ridge - \n'bayesian_ridge'\n\n\n\n\nThe decoding parameters should abide to the following structure:\n\n\ndecoders\n \n=\n \ndict\n(\n\n    \ndecoded_population\n=\n[\nE\n,\n \nE\n,\n \n[\nE\n,\n \nI\n],\n \n[\nE\n,\n \nI\n],\n \nI\n,\n \nI\n],\n\n    \nstate_variable\n=\n[\nV_m\n,\n \nspikes\n,\n \nV_m\n,\n \nspikes\n,\n \nV_m\n,\n \nspikes\n],\n\n    \nfilter_time\n=\nfilter_tau\n,\n\n    \nreadouts\n=\nreadout_labels\n,\n\n    \nreadout_algorithms\n=\n[\nridge\n,\n \nridge\n,\n \nridge\n,\n \nridge\n,\n \nridge\n,\n \nridge\n],\n\n    \nglobal_sampling_times\n=\nstate_sampling\n,\n\n\n)\n\n\ndecoding_pars\n \n=\n \nset_decoding_defaults\n(\ndefault_set\n=\n1\n,\n \n                                      \noutput_resolution\n=\n1.\n,\n \n                                      \nto_memory\n=\nTrue\n,\n \n                                      \nkernel_pars\n=\nkernel_pars\n,\n\n                                      \n**\ndecoders\n)", 
            "title": "Decoding Layer"
        }, 
        {
            "location": "/decoding/#specifying-state-variables", 
            "text": "In the current implementation, one can simultaneously record and readout all relevant variables, for\ncomparison purposes (as long as they are recordable). To do so, we just specify which populations\nto read, and which variable to read from. This is done in the dictionary that is passed as argument to the decoding defaults (see below), namely the key variables  decoded_population  and state_variable .  These two variables need to be lists of equal length. A given decoded_population can be\nspecified as a sub-list, which means that we want to extract 1 state matrix from the combination of\nthe two referred populations (which are merged for this purpose). See example below.", 
            "title": "Specifying state variables"
        }, 
        {
            "location": "/decoding/#state-sampling-methods", 
            "text": "The population responses to the stimuli can also be extracted in various different ways, by taking\nsamples of the state variable under consideration. In the current implementation this is simply done with the decoder variable global_sampling_times:   One-sample at the stimulus offset (default, t* ):  global_sampling_times = None  one population state vector per stimulus    Multiple samples taken at specific times (all stimuli must have the same duration):  global_sampling_times is given as a list of np.array of times (from stimulus onset) - length N*  one population state vector per sampling time  constructs N* state matrices that will be independently readout    Sub-sampling responses at a fixed rate:  global_sampling_times = 1/10 is given as a fraction (one sample every 10 steps, step size being the input resolution)  constructs one long state matrix corresponding to the full response (in the limit, if global_sampling_times = 1, this corresponds to the entire activity history, sampled at the input resolution)  the target is also downsampled to the same rate, implementing an approximation to a continuous readout.     These different methods are used for different purposes, to assess different features of the responses. See Examples. Note that in the current version only the first sampling method is fully implemented and tested.", 
            "title": "State sampling methods"
        }, 
        {
            "location": "/decoding/#readouts", 
            "text": "Currently available algorithms are:   Direct pseudo-inverse -  'pinv'  Ridge Regression -  'ridge'  Logistic Regression -  'logistic'  Perceptron -  'perceptron'  Linear SVM -  'svm-linear'  Non-linear SVM (radial basis function) -  'svm-rbf'  Elastic Net -  'elastic'  Bayesian Ridge -  'bayesian_ridge'   The decoding parameters should abide to the following structure:  decoders   =   dict ( \n     decoded_population = [ E ,   E ,   [ E ,   I ],   [ E ,   I ],   I ,   I ], \n     state_variable = [ V_m ,   spikes ,   V_m ,   spikes ,   V_m ,   spikes ], \n     filter_time = filter_tau , \n     readouts = readout_labels , \n     readout_algorithms = [ ridge ,   ridge ,   ridge ,   ridge ,   ridge ,   ridge ], \n     global_sampling_times = state_sampling ,  )  decoding_pars   =   set_decoding_defaults ( default_set = 1 ,  \n                                       output_resolution = 1. ,  \n                                       to_memory = True ,  \n                                       kernel_pars = kernel_pars , \n                                       ** decoders )", 
            "title": "Readouts"
        }, 
        {
            "location": "/analysis-and-visualization/", 
            "text": "", 
            "title": "Analysis and visualization"
        }, 
        {
            "location": "/single-neuron-fi-curve/", 
            "text": "In this simple example, we perform a very simple and common experiment: determining the responses\nof a single neuron to injected current at different amplitudes. The specific setup is illustrated below\n\n\n\n\nIn this simple setup, one single generator, a \n\u2019step_current_generator\u2019\n is used and a single neuron composes the whole network.\n\n\nTo run this example execute:\n\n\npython\n \nmain\n.\npy\n \n-\nf\n \nprojects\n/\nexamples\n/\nparameters\n/\nsingle_neuron_fI\n.\npy\n \n-\nc\n \nsingle_neuron_fIcurve\n \n--\nextra\n \nplot\n=\nTrue\n \ndisplay\n=\nTrue\n \nsave\n=\nTrue\n\n\n\n\n\n\nThe output should display the neuron's fI curve, as well as a sample of its response (to the first current amplitude that drives the neuron to fire). There are two additional plots that refer to an adaptation index, to determine the degree of irregularity in the inter-spike intervals (primarily for neurons that display an adaptive firing pattern).", 
            "title": "Single neuron fI curve"
        }, 
        {
            "location": "/single-neuron-with-patterned-synaptic-input/", 
            "text": "NOTE:\n to run this example, you need the NEST version containing the inhomogeneous Poisson generator (currently \navailable as a \nPull Request here\n)\n\n\nThis example illustrates one way how input signals can be transformed into spike patterns in the Encoding Layer to \nsimulate synaptic bombardment of neuronal populations (here only a single neuron).  \n\n\n\n\nThe set of input signals is composed of two independent noise channels that will later act as excitatory (blue) and \ninhibitory (red) input, modeled as independent Ornstein-Uhlenbeck \nprocesses. Each of the signals drives one inhomogeneous Poisson generator in the Encoding Layer: at given intervals, \nthese input signals are sampled and the values are used to set / update the firing rate of the generators. This way, \nthe generators transform the input signals into Poisson spike trains that are passed to the encoders. There are two encoders \nin this, consisting of a number of parrot neurons, which means they only forward the incoming spikes to the population they are connected to.\n\n\nNote that, behind the scenes, there are as many NEST spike generators created as the dimensionality the Encoders, so \neach parrot neuron will receive and independent Poisson spike train as input.\n\n\nTo run this example execute:\n\n\npython\n \nmain\n.\npy\n \n-\nf\n \n./\nprojects\n/\nexamples\n/\nparameters\n/\nsingle_neuron_patterned_synaptic_input\n.\npy\n \n-\nc\n \nsingle_neuron_pattern_input\n \n--\nextra\n \nplot\n=\nTrue\n \ndisplay\n=\nFalse\n \nsave\n=\nTrue\n\n\n\n\n\n\nAfter running the example you should see 3 figures: the input signal of the two channels and the main output reporting some statistics for the single neuron:\nhistogram of the inter-spike intervals (ISI), firing rate, coefficient of variation (CV_ISI), Fano Factor, and the time \ncourse of the synaptic current (I_syn) and membrane potential (V_m).", 
            "title": "Single neuron with patterned synaptic input"
        }, 
        {
            "location": "/balanced-random-network/", 
            "text": "This example consists of a balanced random network, driven by Poissonian external input, and is a commonly used setup to characterize population dynamics. The specific setup for this example is illustrated below:\n\n\n\n\nIn this simple setup, one single generator, a \n\u2019poisson_generator\u2019\n is used and connects to all the neurons in the network (note that the generator draws independent realizations of Poisson spike trains at the specified rate for each target neuron). \n\n\nTo run this example execute:\n\n\npython\n \nmain\n.\npy\n \n-\nf\n \nprojects\n/\nexamples\n/\nparameters\n/\nnoise_driven_dynamics\n.\npy\n \n-\nc\n \npopulation_noisedriven\n \n--\nextra\n \nplot\n=\nTrue\n \ndisplay\n=\nTrue\n \nsave\n=\nTrue\n\n\n\n\n\n\nThe output of this analysis, in the simplest case, consists of a raster plot displaying the population spiking activity, mean rates and (if an analog activity recorder is connected) an example of the input synaptic currents and membrane potential of a randomly chosen neuron. In addition, a summarized activity report is displayed.\nThe analysis parameters for this experiment allow the specification of which metrics are applied, as these vary in complexity and required computing time. This is accomplished with the parameter \n\u2019depth\u2019\n, as described in the comments. Note that the most complete characterization can be quite resource- and time-consuming.", 
            "title": "Balanced random network"
        }, 
        {
            "location": "/stimulus-processing/", 
            "text": "This complex example shows the application of the full setup to perform a computational experiment. A random stimulus sequence of length T is constructed and encoded as a sequence of spatiotemporal spike patterns (each stimulus is converted into a fixed set of Poissonian spike trains - an instance of \"frozen noise\"). These input spikes are delivered to the main network (a standard balanced network) via spike generators. The simulation runs in steps, iterating through the input sequence and gathering samples of the chosen population state variable, at stimulus offset (default). \n\n\nNOTE:\n we provide two different, dedicated functions to iterate stimulus sequences (see the \nauxiliary\n module). However, in order to use the faster implementation, which relies on modifying how the recording devices sample the population activity, you need an adapted version of the \nmultimeter\n model (see corresponding issue \nhere\n and pull request \nhere\n)\n\n\nAfter the simulation is completed, the population state in response to the input is compiled in an NxT state matrix, a subset of which is used to train a set of linear readouts, using ridge regression. The remaining subset is used to test the readout accuracy. In this setup, we use 10 parallel readouts, whose target outputs are delayed copies of the input sequence (i.e. we measure the ability to use the system state in response to stimulus n to determine whether it contains information about stimulus history: n-1, n-2, ...).\n\n\nThe complete setup and illustrative results are provided below:\n\n\n\nTo run this example execute:\n\n\npython\n \nmain\n.\npy\n \n-\nf\n \n./\nprojects\n/\nexamples\n/\nparameters\n/\nspike_pattern_input\n.\npy\n \n-\nc\n \nstimulus_processing\n \n--\nextra\n \nplot\n=\nTrue\n \ndisplay\n=\nFalse\n \nsave\n=\nTrue\n\n\n\n\n\n\nIf all goes well, the simulation should run and a detailed output is provided, summarizing what is being done. After completion, since \nsave=True\n, all the relevant data and results are stored in the output folder, including a copy of the original parameters file, a figure similar to that below (main result), the stimulus set used and the state matrices. Additionally, the console output should show the key results. \n\n\n\n\nYou can retrieve the data using the provided \nstimulus_processing_task\n in \nexamples/read_data/\n, which also serves as an example of how to load and harvest simulation results.", 
            "title": "Stimulus processing"
        }, 
        {
            "location": "/release-notes/", 
            "text": "Release notes\n\n\nUpgrading\n\n\nTo determine the currently installed version, use the following command:\n\n\npython main.py --version\n\n\n\n\n\nSince the repository currently only lives on Github, just pull from the master branch to get the latest version. \n\n\nChangelog\n\n\n0.1 \n _ May 21, 2017\n\n\n\n\nInitial release", 
            "title": "Release notes"
        }, 
        {
            "location": "/release-notes/#release-notes", 
            "text": "", 
            "title": "Release notes"
        }, 
        {
            "location": "/release-notes/#upgrading", 
            "text": "To determine the currently installed version, use the following command:  python main.py --version  Since the repository currently only lives on Github, just pull from the master branch to get the latest version.", 
            "title": "Upgrading"
        }, 
        {
            "location": "/release-notes/#changelog", 
            "text": "", 
            "title": "Changelog"
        }, 
        {
            "location": "/release-notes/#01-_-may-21-2017", 
            "text": "Initial release", 
            "title": "0.1  _ May 21, 2017"
        }, 
        {
            "location": "/contributing/", 
            "text": "Contributing\n\n\nInterested in contributing to the NMSAT framework? Want to report a bug? Before\nyou do, please read the following guidelines.\n\n\nSubmission context\n\n\nGot a question or problem?\n\n\nFor quick questions there's no need to open an issue as you can reach us via email at \n\n\n\n\n\n\n\n\n\n\nFound a bug?\n\n\nIf you found a bug in the source code, you can help us by submitting an issue\nto the \nissue tracker\n in our GitHub repository. Even better, you can submit\na Pull Request with a fix. However, before doing so, please read the\n\nsubmission guidelines\n.\n\n\nMissing a feature?\n\n\nNMSAT is continuously being developed and ideas for new features are most welcome! \nYou can request a new feature by submitting an issue to our GitHub Repository.\nIf you would like to implement a new feature, please submit an issue with a\nproposal for your work first . Please consider what kind of change\nit is:\n\n\n\n\n\n\nFor a \nmajor feature\n, first open an issue and outline your proposal so\n  that it can be discussed. This will also allow us to better coordinate our\n  efforts, prevent duplication of work, and help you to craft the change so\n  that it is successfully accepted into the project.\n\n\n\n\n\n\nSmall features and bugs\n can be crafted and directly submitted as a Pull\n  Request, which will be merged into the master branch after a review by the \n  core developers. \n\n\n\n\n\n\nSubmission guidelines\n\n\nSubmitting an issue\n\n\nBefore you submit an issue, please search the issue tracker, maybe an issue for\nyour problem already exists and the discussion might inform you of workarounds\nreadily available.\n\n\nWe want to fix all the issues as soon as possible, but before fixing a bug we\nneed to reproduce and confirm it. In order to reproduce bugs we will\nsystematically ask you to provide a minimal reproduction scenario using the\nparameter file. Please stick to the issue template.\n\n\n\n\n\n\n\n\nSubmitting a Pull Request (PR)\n\n\nSearch GitHub for an open or closed PR that relates to your submission. You\ndon't want to duplicate effort. If you do not find a related issue or PR,\ngo ahead.\n\n\n\n\n\n\nDevelopment\n: Fork the project, make your changes in a separate git branch \n  and add descriptive messages to your commits.\n\n\n\n\n\n\nPull Request\n: After committing your changes, push\n  your branch to GitHub and send a PR to \nnmsat:master\n. If we\n  suggest changes, make the required updates, rebase your branch and push the\n  changes to your GitHub repository, which will automatically update your PR.\n\n\n\n\n\n\nAfter your PR is merged, you can safely delete your branch and pull the changes\nfrom the main (upstream) repository.", 
            "title": "Contributing"
        }, 
        {
            "location": "/contributing/#contributing", 
            "text": "Interested in contributing to the NMSAT framework? Want to report a bug? Before\nyou do, please read the following guidelines.", 
            "title": "Contributing"
        }, 
        {
            "location": "/contributing/#submission-context", 
            "text": "", 
            "title": "Submission context"
        }, 
        {
            "location": "/contributing/#got-a-question-or-problem", 
            "text": "For quick questions there's no need to open an issue as you can reach us via email at", 
            "title": "Got a question or problem?"
        }, 
        {
            "location": "/contributing/#found-a-bug", 
            "text": "If you found a bug in the source code, you can help us by submitting an issue\nto the  issue tracker  in our GitHub repository. Even better, you can submit\na Pull Request with a fix. However, before doing so, please read the submission guidelines .", 
            "title": "Found a bug?"
        }, 
        {
            "location": "/contributing/#missing-a-feature", 
            "text": "NMSAT is continuously being developed and ideas for new features are most welcome! \nYou can request a new feature by submitting an issue to our GitHub Repository.\nIf you would like to implement a new feature, please submit an issue with a\nproposal for your work first . Please consider what kind of change\nit is:    For a  major feature , first open an issue and outline your proposal so\n  that it can be discussed. This will also allow us to better coordinate our\n  efforts, prevent duplication of work, and help you to craft the change so\n  that it is successfully accepted into the project.    Small features and bugs  can be crafted and directly submitted as a Pull\n  Request, which will be merged into the master branch after a review by the \n  core developers.", 
            "title": "Missing a feature?"
        }, 
        {
            "location": "/contributing/#submission-guidelines", 
            "text": "", 
            "title": "Submission guidelines"
        }, 
        {
            "location": "/contributing/#submitting-an-issue", 
            "text": "Before you submit an issue, please search the issue tracker, maybe an issue for\nyour problem already exists and the discussion might inform you of workarounds\nreadily available.  We want to fix all the issues as soon as possible, but before fixing a bug we\nneed to reproduce and confirm it. In order to reproduce bugs we will\nsystematically ask you to provide a minimal reproduction scenario using the\nparameter file. Please stick to the issue template.", 
            "title": "Submitting an issue"
        }, 
        {
            "location": "/contributing/#submitting-a-pull-request-pr", 
            "text": "Search GitHub for an open or closed PR that relates to your submission. You\ndon't want to duplicate effort. If you do not find a related issue or PR,\ngo ahead.    Development : Fork the project, make your changes in a separate git branch \n  and add descriptive messages to your commits.    Pull Request : After committing your changes, push\n  your branch to GitHub and send a PR to  nmsat:master . If we\n  suggest changes, make the required updates, rebase your branch and push the\n  changes to your GitHub repository, which will automatically update your PR.    After your PR is merged, you can safely delete your branch and pull the changes\nfrom the main (upstream) repository.", 
            "title": "Submitting a Pull Request (PR)"
        }, 
        {
            "location": "/license/", 
            "text": "Copyright \n 2017 Renato Duarte \n\n\nGNU GENERAL PUBLIC LICENSE\n\n\nVersion 3, 29 June 2007\n\n\nCopyright (C) 2007 Free Software Foundation, Inc.\n\nhttp://fsf.org/\n\n\nEveryone is permitted to copy and distribute verbatim copies of this\nlicense document, but changing it is not allowed.\n\n\nPreamble\n\n\nThe GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n\nThe licenses for most software and other practical works are designed\nto take away your freedom to share and change the works. By contrast,\nthe GNU General Public License is intended to guarantee your freedom\nto share and change all versions of a program--to make sure it remains\nfree software for all its users. We, the Free Software Foundation, use\nthe GNU General Public License for most of our software; it applies\nalso to any other work released this way by its authors. You can apply\nit to your programs, too.\n\n\nWhen we speak of free software, we are referring to freedom, not\nprice. Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n\nTo protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights. Therefore, you\nhave certain responsibilities if you distribute copies of the\nsoftware, or if you modify it: responsibilities to respect the freedom\nof others.\n\n\nFor example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received. You must make sure that they, too, receive\nor can get the source code. And you must show them these terms so they\nknow their rights.\n\n\nDevelopers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n\nFor the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software. For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n\nSome devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the\nmanufacturer can do so. This is fundamentally incompatible with the\naim of protecting users' freedom to change the software. The\nsystematic pattern of such abuse occurs in the area of products for\nindividuals to use, which is precisely where it is most unacceptable.\nTherefore, we have designed this version of the GPL to prohibit the\npractice for those products. If such problems arise substantially in\nother domains, we stand ready to extend this provision to those\ndomains in future versions of the GPL, as needed to protect the\nfreedom of users.\n\n\nFinally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish\nto avoid the special danger that patents applied to a free program\ncould make it effectively proprietary. To prevent this, the GPL\nassures that patents cannot be used to render the program non-free.\n\n\nThe precise terms and conditions for copying, distribution and\nmodification follow.\n\n\nTERMS AND CONDITIONS\n\n\n0. Definitions.\n\n\n\"This License\" refers to version 3 of the GNU General Public License.\n\n\n\"Copyright\" also means copyright-like laws that apply to other kinds\nof works, such as semiconductor masks.\n\n\n\"The Program\" refers to any copyrightable work licensed under this\nLicense. Each licensee is addressed as \"you\". \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n\nTo \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of\nan exact copy. The resulting work is called a \"modified version\" of\nthe earlier work or a work \"based on\" the earlier work.\n\n\nA \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n\nTo \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy. Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n\nTo \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies. Mere interaction with a user\nthrough a computer network, with no transfer of a copy, is not\nconveying.\n\n\nAn interactive user interface displays \"Appropriate Legal Notices\" to\nthe extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License. If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n\n1. Source Code.\n\n\nThe \"source code\" for a work means the preferred form of the work for\nmaking modifications to it. \"Object code\" means any non-source form of\na work.\n\n\nA \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n\nThe \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form. A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n\nThe \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities. However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work. For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n\nThe Corresponding Source need not include anything that users can\nregenerate automatically from other parts of the Corresponding Source.\n\n\nThe Corresponding Source for a work in source code form is that same\nwork.\n\n\n2. Basic Permissions.\n\n\nAll rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met. This License explicitly affirms your unlimited\npermission to run the unmodified Program. The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work. This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n\nYou may make, run and propagate covered works that you do not convey,\nwithout conditions so long as your license otherwise remains in force.\nYou may convey covered works to others for the sole purpose of having\nthem make modifications exclusively for you, or provide you with\nfacilities for running those works, provided that you comply with the\nterms of this License in conveying all material for which you do not\ncontrol copyright. Those thus making or running the covered works for\nyou must do so exclusively on your behalf, under your direction and\ncontrol, on terms that prohibit them from making any copies of your\ncopyrighted material outside their relationship with you.\n\n\nConveying under any other circumstances is permitted solely under the\nconditions stated below. Sublicensing is not allowed; section 10 makes\nit unnecessary.\n\n\n3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n\nNo covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n\nWhen you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such\ncircumvention is effected by exercising rights under this License with\nrespect to the covered work, and you disclaim any intention to limit\noperation or modification of the work as a means of enforcing, against\nthe work's users, your or third parties' legal rights to forbid\ncircumvention of technological measures.\n\n\n4. Conveying Verbatim Copies.\n\n\nYou may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n\nYou may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n\n5. Conveying Modified Source Versions.\n\n\nYou may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these\nconditions:\n\n\n\n\na) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n\nb) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under\n    section 7. This requirement modifies the requirement in section 4\n    to \"keep intact all notices\".\n\n\nc) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy. This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged. This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n\nd) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n\n\n\nA compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit. Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n\n6. Conveying Non-Source Forms.\n\n\nYou may convey a covered work in object code form under the terms of\nsections 4 and 5, provided that you also convey the machine-readable\nCorresponding Source under the terms of this License, in one of these\nways:\n\n\n\n\na) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n\nb) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the Corresponding\n    Source from a network server at no charge.\n\n\nc) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source. This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n\nd) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge. You need not require recipients to copy the\n    Corresponding Source along with the object code. If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source. Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n\ne) Convey the object code using peer-to-peer transmission,\n    provided you inform other peers where the object code and\n    Corresponding Source of the work are being offered to the general\n    public at no charge under subsection 6d.\n\n\n\n\nA separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n\nA \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal,\nfamily, or household purposes, or (2) anything designed or sold for\nincorporation into a dwelling. In determining whether a product is a\nconsumer product, doubtful cases shall be resolved in favor of\ncoverage. For a particular product received by a particular user,\n\"normally used\" refers to a typical or common use of that class of\nproduct, regardless of the status of the particular user or of the way\nin which the particular user actually uses, or expects or is expected\nto use, the product. A product is a consumer product regardless of\nwhether the product has substantial commercial, industrial or\nnon-consumer uses, unless such uses represent the only significant\nmode of use of the product.\n\n\n\"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to\ninstall and execute modified versions of a covered work in that User\nProduct from a modified version of its Corresponding Source. The\ninformation must suffice to ensure that the continued functioning of\nthe modified object code is in no case prevented or interfered with\nsolely because modification has been made.\n\n\nIf you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information. But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n\nThe requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or\nupdates for a work that has been modified or installed by the\nrecipient, or for the User Product in which it has been modified or\ninstalled. Access to a network may be denied when the modification\nitself materially and adversely affects the operation of the network\nor violates the rules and protocols for communication across the\nnetwork.\n\n\nCorresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n\n7. Additional Terms.\n\n\n\"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law. If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n\nWhen you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit. (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.) You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n\nNotwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders\nof that material) supplement the terms of this License with terms:\n\n\n\n\na) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n\nb) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n\nc) Prohibiting misrepresentation of the origin of that material,\n    or requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n\nd) Limiting the use for publicity purposes of names of licensors\n    or authors of the material; or\n\n\ne) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n\nf) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions\n    of it) with contractual assumptions of liability to the recipient,\n    for any liability that these contractual assumptions directly\n    impose on those licensors and authors.\n\n\n\n\nAll other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10. If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term. If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n\nIf you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n\nAdditional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions; the\nabove requirements apply either way.\n\n\n8. Termination.\n\n\nYou may not propagate or modify a covered work except as expressly\nprovided under this License. Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n\nHowever, if you cease all violation of this License, then your license\nfrom a particular copyright holder is reinstated (a) provisionally,\nunless and until the copyright holder explicitly and finally\nterminates your license, and (b) permanently, if the copyright holder\nfails to notify you of the violation by some reasonable means prior to\n60 days after the cessation.\n\n\nMoreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n\nTermination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License. If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n\n9. Acceptance Not Required for Having Copies.\n\n\nYou are not required to accept this License in order to receive or run\na copy of the Program. Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance. However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work. These actions infringe copyright if you do\nnot accept this License. Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n\n10. Automatic Licensing of Downstream Recipients.\n\n\nEach time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License. You are not responsible\nfor enforcing compliance by third parties with this License.\n\n\nAn \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations. If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n\nYou may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License. For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n\n11. Patents.\n\n\nA \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based. The\nwork thus licensed is called the contributor's \"contributor version\".\n\n\nA contributor's \"essential patent claims\" are all patent claims owned\nor controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version. For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n\nEach contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n\nIn the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement). To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n\nIf you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients. \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n\nIf, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n\nA patent license is \"discriminatory\" if it does not include within the\nscope of its coverage, prohibits the exercise of, or is conditioned on\nthe non-exercise of one or more of the rights that are specifically\ngranted under this License. You may not convey a covered work if you\nare a party to an arrangement with a third party that is in the\nbusiness of distributing software, under which you make payment to the\nthird party based on the extent of your activity of conveying the\nwork, and under which the third party grants, to any of the parties\nwho would receive the covered work from you, a discriminatory patent\nlicense (a) in connection with copies of the covered work conveyed by\nyou (or copies made from those copies), or (b) primarily for and in\nconnection with specific products or compilations that contain the\ncovered work, unless you entered into that arrangement, or that patent\nlicense was granted, prior to 28 March 2007.\n\n\nNothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n\n12. No Surrender of Others' Freedom.\n\n\nIf conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License. If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under\nthis License and any other pertinent obligations, then as a\nconsequence you may not convey it at all. For example, if you agree to\nterms that obligate you to collect a royalty for further conveying\nfrom those to whom you convey the Program, the only way you could\nsatisfy both those terms and this License would be to refrain entirely\nfrom conveying the Program.\n\n\n13. Use with the GNU Affero General Public License.\n\n\nNotwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work. The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n\n14. Revised Versions of this License.\n\n\nThe Free Software Foundation may publish revised and/or new versions\nof the GNU General Public License from time to time. Such new versions\nwill be similar in spirit to the present version, but may differ in\ndetail to address new problems or concerns.\n\n\nEach version is given a distinguishing version number. If the Program\nspecifies that a certain numbered version of the GNU General Public\nLicense \"or any later version\" applies to it, you have the option of\nfollowing the terms and conditions either of that numbered version or\nof any later version published by the Free Software Foundation. If the\nProgram does not specify a version number of the GNU General Public\nLicense, you may choose any version ever published by the Free\nSoftware Foundation.\n\n\nIf the Program specifies that a proxy can decide which future versions\nof the GNU General Public License can be used, that proxy's public\nstatement of acceptance of a version permanently authorizes you to\nchoose that version for the Program.\n\n\nLater license versions may give you additional or different\npermissions. However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n\n15. Disclaimer of Warranty.\n\n\nTHERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT\nWARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND\nPERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE\nDEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR\nCORRECTION.\n\n\n16. Limitation of Liability.\n\n\nIN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR\nCONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,\nINCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES\nARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT\nNOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR\nLOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM\nTO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER\nPARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\n\n17. Interpretation of Sections 15 and 16.\n\n\nIf the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n\nEND OF TERMS AND CONDITIONS\n\n\nHow to Apply These Terms to Your New Programs\n\n\nIf you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these\nterms.\n\n\nTo do so, attach the following notices to the program. It is safest to\nattach them to the start of each source file to most effectively state\nthe exclusion of warranty; and each file should have at least the\n\"copyright\" line and a pointer to where the full notice is found.\n\n\n    \none line to give the program\ns name and a brief idea of what it does.\n\n    Copyright (C) \nyear\n  \nname of author\n\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see \nhttp://www.gnu.org/licenses/\n.\n\n\n\n\n\nAlso add information on how to contact you by electronic and paper\nmail.\n\n\nIf the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n\n    \nprogram\n  Copyright (C) \nyear\n  \nname of author\n\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w\n.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c\n for details.\n\n\n\n\n\nThe hypothetical commands `show w' and `show c' should show the\nappropriate parts of the General Public License. Of course, your\nprogram's commands might be different; for a GUI interface, you would\nuse an \"about box\".\n\n\nYou should also get your employer (if you work as a programmer) or\nschool, if any, to sign a \"copyright disclaimer\" for the program, if\nnecessary. For more information on this, and how to apply and follow\nthe GNU GPL, see \nhttp://www.gnu.org/licenses/\n.\n\n\nThe GNU General Public License does not permit incorporating your\nprogram into proprietary programs. If your program is a subroutine\nlibrary, you may consider it more useful to permit linking proprietary\napplications with the library. If this is what you want to do, use the\nGNU Lesser General Public License instead of this License. But first,\nplease read \nhttp://www.gnu.org/philosophy/why-not-lgpl.html\n.", 
            "title": "License"
        }, 
        {
            "location": "/license/#gnu-general-public-license", 
            "text": "Version 3, 29 June 2007  Copyright (C) 2007 Free Software Foundation, Inc. http://fsf.org/  Everyone is permitted to copy and distribute verbatim copies of this\nlicense document, but changing it is not allowed.", 
            "title": "GNU GENERAL PUBLIC LICENSE"
        }, 
        {
            "location": "/license/#preamble", 
            "text": "The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works. By contrast,\nthe GNU General Public License is intended to guarantee your freedom\nto share and change all versions of a program--to make sure it remains\nfree software for all its users. We, the Free Software Foundation, use\nthe GNU General Public License for most of our software; it applies\nalso to any other work released this way by its authors. You can apply\nit to your programs, too.  When we speak of free software, we are referring to freedom, not\nprice. Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights. Therefore, you\nhave certain responsibilities if you distribute copies of the\nsoftware, or if you modify it: responsibilities to respect the freedom\nof others.  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received. You must make sure that they, too, receive\nor can get the source code. And you must show them these terms so they\nknow their rights.  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software. For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the\nmanufacturer can do so. This is fundamentally incompatible with the\naim of protecting users' freedom to change the software. The\nsystematic pattern of such abuse occurs in the area of products for\nindividuals to use, which is precisely where it is most unacceptable.\nTherefore, we have designed this version of the GPL to prohibit the\npractice for those products. If such problems arise substantially in\nother domains, we stand ready to extend this provision to those\ndomains in future versions of the GPL, as needed to protect the\nfreedom of users.  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish\nto avoid the special danger that patents applied to a free program\ncould make it effectively proprietary. To prevent this, the GPL\nassures that patents cannot be used to render the program non-free.  The precise terms and conditions for copying, distribution and\nmodification follow.", 
            "title": "Preamble"
        }, 
        {
            "location": "/license/#terms-and-conditions", 
            "text": "", 
            "title": "TERMS AND CONDITIONS"
        }, 
        {
            "location": "/license/#0-definitions", 
            "text": "\"This License\" refers to version 3 of the GNU General Public License.  \"Copyright\" also means copyright-like laws that apply to other kinds\nof works, such as semiconductor masks.  \"The Program\" refers to any copyrightable work licensed under this\nLicense. Each licensee is addressed as \"you\". \"Licensees\" and\n\"recipients\" may be individuals or organizations.  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of\nan exact copy. The resulting work is called a \"modified version\" of\nthe earlier work or a work \"based on\" the earlier work.  A \"covered work\" means either the unmodified Program or a work based\non the Program.  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy. Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies. Mere interaction with a user\nthrough a computer network, with no transfer of a copy, is not\nconveying.  An interactive user interface displays \"Appropriate Legal Notices\" to\nthe extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License. If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.", 
            "title": "0. Definitions."
        }, 
        {
            "location": "/license/#1-source-code", 
            "text": "The \"source code\" for a work means the preferred form of the work for\nmaking modifications to it. \"Object code\" means any non-source form of\na work.  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form. A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities. However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work. For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.  The Corresponding Source need not include anything that users can\nregenerate automatically from other parts of the Corresponding Source.  The Corresponding Source for a work in source code form is that same\nwork.", 
            "title": "1. Source Code."
        }, 
        {
            "location": "/license/#2-basic-permissions", 
            "text": "All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met. This License explicitly affirms your unlimited\npermission to run the unmodified Program. The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work. This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.  You may make, run and propagate covered works that you do not convey,\nwithout conditions so long as your license otherwise remains in force.\nYou may convey covered works to others for the sole purpose of having\nthem make modifications exclusively for you, or provide you with\nfacilities for running those works, provided that you comply with the\nterms of this License in conveying all material for which you do not\ncontrol copyright. Those thus making or running the covered works for\nyou must do so exclusively on your behalf, under your direction and\ncontrol, on terms that prohibit them from making any copies of your\ncopyrighted material outside their relationship with you.  Conveying under any other circumstances is permitted solely under the\nconditions stated below. Sublicensing is not allowed; section 10 makes\nit unnecessary.", 
            "title": "2. Basic Permissions."
        }, 
        {
            "location": "/license/#3-protecting-users-legal-rights-from-anti-circumvention-law", 
            "text": "No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such\ncircumvention is effected by exercising rights under this License with\nrespect to the covered work, and you disclaim any intention to limit\noperation or modification of the work as a means of enforcing, against\nthe work's users, your or third parties' legal rights to forbid\ncircumvention of technological measures.", 
            "title": "3. Protecting Users' Legal Rights From Anti-Circumvention Law."
        }, 
        {
            "location": "/license/#4-conveying-verbatim-copies", 
            "text": "You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.", 
            "title": "4. Conveying Verbatim Copies."
        }, 
        {
            "location": "/license/#5-conveying-modified-source-versions", 
            "text": "You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these\nconditions:   a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.  b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under\n    section 7. This requirement modifies the requirement in section 4\n    to \"keep intact all notices\".  c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy. This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged. This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.  d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.   A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit. Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.", 
            "title": "5. Conveying Modified Source Versions."
        }, 
        {
            "location": "/license/#6-conveying-non-source-forms", 
            "text": "You may convey a covered work in object code form under the terms of\nsections 4 and 5, provided that you also convey the machine-readable\nCorresponding Source under the terms of this License, in one of these\nways:   a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.  b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the Corresponding\n    Source from a network server at no charge.  c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source. This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.  d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge. You need not require recipients to copy the\n    Corresponding Source along with the object code. If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source. Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.  e) Convey the object code using peer-to-peer transmission,\n    provided you inform other peers where the object code and\n    Corresponding Source of the work are being offered to the general\n    public at no charge under subsection 6d.   A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal,\nfamily, or household purposes, or (2) anything designed or sold for\nincorporation into a dwelling. In determining whether a product is a\nconsumer product, doubtful cases shall be resolved in favor of\ncoverage. For a particular product received by a particular user,\n\"normally used\" refers to a typical or common use of that class of\nproduct, regardless of the status of the particular user or of the way\nin which the particular user actually uses, or expects or is expected\nto use, the product. A product is a consumer product regardless of\nwhether the product has substantial commercial, industrial or\nnon-consumer uses, unless such uses represent the only significant\nmode of use of the product.  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to\ninstall and execute modified versions of a covered work in that User\nProduct from a modified version of its Corresponding Source. The\ninformation must suffice to ensure that the continued functioning of\nthe modified object code is in no case prevented or interfered with\nsolely because modification has been made.  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information. But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or\nupdates for a work that has been modified or installed by the\nrecipient, or for the User Product in which it has been modified or\ninstalled. Access to a network may be denied when the modification\nitself materially and adversely affects the operation of the network\nor violates the rules and protocols for communication across the\nnetwork.  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.", 
            "title": "6. Conveying Non-Source Forms."
        }, 
        {
            "location": "/license/#7-additional-terms", 
            "text": "\"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law. If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit. (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.) You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders\nof that material) supplement the terms of this License with terms:   a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or  b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or  c) Prohibiting misrepresentation of the origin of that material,\n    or requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or  d) Limiting the use for publicity purposes of names of licensors\n    or authors of the material; or  e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or  f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions\n    of it) with contractual assumptions of liability to the recipient,\n    for any liability that these contractual assumptions directly\n    impose on those licensors and authors.   All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10. If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term. If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions; the\nabove requirements apply either way.", 
            "title": "7. Additional Terms."
        }, 
        {
            "location": "/license/#8-termination", 
            "text": "You may not propagate or modify a covered work except as expressly\nprovided under this License. Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).  However, if you cease all violation of this License, then your license\nfrom a particular copyright holder is reinstated (a) provisionally,\nunless and until the copyright holder explicitly and finally\nterminates your license, and (b) permanently, if the copyright holder\nfails to notify you of the violation by some reasonable means prior to\n60 days after the cessation.  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License. If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.", 
            "title": "8. Termination."
        }, 
        {
            "location": "/license/#9-acceptance-not-required-for-having-copies", 
            "text": "You are not required to accept this License in order to receive or run\na copy of the Program. Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance. However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work. These actions infringe copyright if you do\nnot accept this License. Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.", 
            "title": "9. Acceptance Not Required for Having Copies."
        }, 
        {
            "location": "/license/#10-automatic-licensing-of-downstream-recipients", 
            "text": "Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License. You are not responsible\nfor enforcing compliance by third parties with this License.  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations. If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License. For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.", 
            "title": "10. Automatic Licensing of Downstream Recipients."
        }, 
        {
            "location": "/license/#11-patents", 
            "text": "A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based. The\nwork thus licensed is called the contributor's \"contributor version\".  A contributor's \"essential patent claims\" are all patent claims owned\nor controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version. For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement). To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients. \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.  A patent license is \"discriminatory\" if it does not include within the\nscope of its coverage, prohibits the exercise of, or is conditioned on\nthe non-exercise of one or more of the rights that are specifically\ngranted under this License. You may not convey a covered work if you\nare a party to an arrangement with a third party that is in the\nbusiness of distributing software, under which you make payment to the\nthird party based on the extent of your activity of conveying the\nwork, and under which the third party grants, to any of the parties\nwho would receive the covered work from you, a discriminatory patent\nlicense (a) in connection with copies of the covered work conveyed by\nyou (or copies made from those copies), or (b) primarily for and in\nconnection with specific products or compilations that contain the\ncovered work, unless you entered into that arrangement, or that patent\nlicense was granted, prior to 28 March 2007.  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.", 
            "title": "11. Patents."
        }, 
        {
            "location": "/license/#12-no-surrender-of-others-freedom", 
            "text": "If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License. If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under\nthis License and any other pertinent obligations, then as a\nconsequence you may not convey it at all. For example, if you agree to\nterms that obligate you to collect a royalty for further conveying\nfrom those to whom you convey the Program, the only way you could\nsatisfy both those terms and this License would be to refrain entirely\nfrom conveying the Program.", 
            "title": "12. No Surrender of Others' Freedom."
        }, 
        {
            "location": "/license/#13-use-with-the-gnu-affero-general-public-license", 
            "text": "Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work. The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.", 
            "title": "13. Use with the GNU Affero General Public License."
        }, 
        {
            "location": "/license/#14-revised-versions-of-this-license", 
            "text": "The Free Software Foundation may publish revised and/or new versions\nof the GNU General Public License from time to time. Such new versions\nwill be similar in spirit to the present version, but may differ in\ndetail to address new problems or concerns.  Each version is given a distinguishing version number. If the Program\nspecifies that a certain numbered version of the GNU General Public\nLicense \"or any later version\" applies to it, you have the option of\nfollowing the terms and conditions either of that numbered version or\nof any later version published by the Free Software Foundation. If the\nProgram does not specify a version number of the GNU General Public\nLicense, you may choose any version ever published by the Free\nSoftware Foundation.  If the Program specifies that a proxy can decide which future versions\nof the GNU General Public License can be used, that proxy's public\nstatement of acceptance of a version permanently authorizes you to\nchoose that version for the Program.  Later license versions may give you additional or different\npermissions. However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.", 
            "title": "14. Revised Versions of this License."
        }, 
        {
            "location": "/license/#15-disclaimer-of-warranty", 
            "text": "THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT\nWARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND\nPERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE\nDEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR\nCORRECTION.", 
            "title": "15. Disclaimer of Warranty."
        }, 
        {
            "location": "/license/#16-limitation-of-liability", 
            "text": "IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR\nCONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,\nINCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES\nARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT\nNOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR\nLOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM\nTO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER\nPARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.", 
            "title": "16. Limitation of Liability."
        }, 
        {
            "location": "/license/#17-interpretation-of-sections-15-and-16", 
            "text": "If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.  END OF TERMS AND CONDITIONS", 
            "title": "17. Interpretation of Sections 15 and 16."
        }, 
        {
            "location": "/license/#how-to-apply-these-terms-to-your-new-programs", 
            "text": "If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these\nterms.  To do so, attach the following notices to the program. It is safest to\nattach them to the start of each source file to most effectively state\nthe exclusion of warranty; and each file should have at least the\n\"copyright\" line and a pointer to where the full notice is found.       one line to give the program s name and a brief idea of what it does. \n    Copyright (C)  year    name of author \n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see  http://www.gnu.org/licenses/ .  Also add information on how to contact you by electronic and paper\nmail.  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:       program   Copyright (C)  year    name of author \n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w .\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c  for details.  The hypothetical commands `show w' and `show c' should show the\nappropriate parts of the General Public License. Of course, your\nprogram's commands might be different; for a GUI interface, you would\nuse an \"about box\".  You should also get your employer (if you work as a programmer) or\nschool, if any, to sign a \"copyright disclaimer\" for the program, if\nnecessary. For more information on this, and how to apply and follow\nthe GNU GPL, see  http://www.gnu.org/licenses/ .  The GNU General Public License does not permit incorporating your\nprogram into proprietary programs. If your program is a subroutine\nlibrary, you may consider it more useful to permit linking proprietary\napplications with the library. If this is what you want to do, use the\nGNU Lesser General Public License instead of this License. But first,\nplease read  http://www.gnu.org/philosophy/why-not-lgpl.html .", 
            "title": "How to Apply These Terms to Your New Programs"
        }
    ]
}